2025-04-04 15:07:20.102267: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2025-04-04 15:07:20.296578: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2025-04-04 15:07:20.360464: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-04-04 15:07:21.099985: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-04-04 15:07:40.852135: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/home/ulaval.ca/maelr5/parkinsons/parksenv/lib/python3.11/site-packages/transformers/configuration_utils.py:315: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.
  warnings.warn(
speechbrain.lobes.models.huggingface_transformers.wav2vec2 - wav2vec 2.0 feature extractor is frozen.
speechbrain.utils.quirks - Applied quirks (see `speechbrain.utils.quirks`): [disable_jit_profiling, allow_tf32]
speechbrain.utils.quirks - Excluded quirks specified by the `SB_DISABLE_QUIRKS` environment (comma-separated list): []
speechbrain.core - Beginning experiment!
speechbrain.core - Experiment folder: /home/ulaval.ca/maelr5/scratch/parkinsons-results/train_with_wav2vec2/base/1986
speechbrain.dataio.encoder - Load called, but CategoricalEncoder is not empty. Loaded data will overwrite everything. This is normal if there is e.g. an unk label defined at init.
Class Labels: ['Healthy Control', "with Parkinson's disease"] [0, 1]
speechbrain.core - Gradscaler enabled: `False`
speechbrain.core - Using training precision: `--precision=fp32`
speechbrain.core - Using evaluation precision: `--eval_precision=fp32`
speechbrain.core - DetectorBrain Model Statistics:
* Total Number of Trainable Parameters: 90.2M
* Total Number of Parameters: 94.4M
* Trainable Parameters represent 95.5491% of the total size.
speechbrain.utils.checkpoints - Would load a checkpoint here, but none found yet.
speechbrain.utils.epoch_loop - Going into epoch 1
  0%|          | 0/1 [00:00<?, ?it/s]                                       0%|          | 0/1 [00:00<?, ?it/s]wav length =  105
speechbrain.dataio.encoder - CategoricalEncoder.expect_len was never called: assuming category count of 2 to be correct! Sanity check your encoder using `.expect_len`. Ensure that downstream code also uses the correct size. If you are sure this does not apply to you, use `.ignore_len`.
  0%|          | 0/1 [00:10<?, ?it/s, train_loss=0.768]100%|██████████| 1/1 [00:10<00:00, 10.00s/it, train_loss=0.768]wav length =  119
100%|██████████| 1/1 [00:10<00:00, 10.03s/it, train_loss=0.768]
predictions shape=  torch.Size([2, 2])
detection_id shape=  torch.Size([2])
prediction tensor([[-0.7973, -0.5988],
        [-0.9377, -0.4968]], device='cuda:0', grad_fn=<LogSoftmaxBackward0>)
detection_id tensor([1, 0], device='cuda:0')
Predictions shape: torch.Size([2, 2])
Detection ID shape: torch.Size([2])
Lengths shape: torch.Size([2])
Predictions after argmax shape: torch.Size([2, 1, 2])
Detection ID target shape: torch.Size([2, 1])
  0%|          | 0/1 [00:00<?, ?it/s]                                       0%|          | 0/1 [00:00<?, ?it/s]wav length =  107
speechbrain.dataio.encoder - CategoricalEncoder.expect_len was never called: assuming category count of 2 to be correct! Sanity check your encoder using `.expect_len`. Ensure that downstream code also uses the correct size. If you are sure this does not apply to you, use `.ignore_len`.
100%|██████████| 1/1 [00:00<00:00,  2.07it/s]wav length =  110
100%|██████████| 1/1 [00:00<00:00,  1.95it/s]
predictions shape=  torch.Size([2, 2])
detection_id shape=  torch.Size([2])
prediction tensor([[-0.8219, -0.5791],
        [-0.6018, -0.7936]], device='cuda:0')
detection_id tensor([1, 1], device='cuda:0')
Predictions shape: torch.Size([2, 2])
Detection ID shape: torch.Size([2])
Lengths shape: torch.Size([2])
Predictions after argmax shape: torch.Size([2, 1, 2])
Detection ID target shape: torch.Size([2, 1])
speechbrain.utils.train_logger - Epoch: 1, lr: 1.00e-04, ssl_lr: 1.00e-05 - train loss: 7.68e-01 - valid loss: 6.86e-01, valid acc: 5.00e-01, valid error_rate: 5.00e-01
speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /home/ulaval.ca/maelr5/scratch/parkinsons-results/train_with_wav2vec2/base/1986/save/CKPT+2025-04-04+15-08-48+00
speechbrain.utils.epoch_loop - Going into epoch 2
  0%|          | 0/1 [00:00<?, ?it/s]                                       0%|          | 0/1 [00:00<?, ?it/s]wav length =  105
speechbrain.dataio.encoder - CategoricalEncoder.expect_len was never called: assuming category count of 2 to be correct! Sanity check your encoder using `.expect_len`. Ensure that downstream code also uses the correct size. If you are sure this does not apply to you, use `.ignore_len`.
  0%|          | 0/1 [00:01<?, ?it/s, train_loss=0.542]100%|██████████| 1/1 [00:01<00:00,  1.12s/it, train_loss=0.542]wav length =  119
100%|██████████| 1/1 [00:01<00:00,  1.15s/it, train_loss=0.542]
predictions shape=  torch.Size([2, 2])
detection_id shape=  torch.Size([2])
prediction tensor([[-0.7521, -0.6374],
        [-0.4474, -1.0198]], device='cuda:0', grad_fn=<LogSoftmaxBackward0>)
detection_id tensor([1, 0], device='cuda:0')
Predictions shape: torch.Size([2, 2])
Detection ID shape: torch.Size([2])
Lengths shape: torch.Size([2])
Predictions after argmax shape: torch.Size([2, 1, 2])
Detection ID target shape: torch.Size([2, 1])
  0%|          | 0/1 [00:00<?, ?it/s]                                       0%|          | 0/1 [00:00<?, ?it/s]wav length =  107
speechbrain.dataio.encoder - CategoricalEncoder.expect_len was never called: assuming category count of 2 to be correct! Sanity check your encoder using `.expect_len`. Ensure that downstream code also uses the correct size. If you are sure this does not apply to you, use `.ignore_len`.
100%|██████████| 1/1 [00:00<00:00,  2.61it/s]wav length =  110
100%|██████████| 1/1 [00:00<00:00,  2.43it/s]
predictions shape=  torch.Size([2, 2])
detection_id shape=  torch.Size([2])
prediction tensor([[-0.8313, -0.5718],
        [-0.3441, -1.2338]], device='cuda:0')
detection_id tensor([1, 1], device='cuda:0')
Predictions shape: torch.Size([2, 2])
Detection ID shape: torch.Size([2])
Lengths shape: torch.Size([2])
Predictions after argmax shape: torch.Size([2, 1, 2])
Detection ID target shape: torch.Size([2, 1])
speechbrain.nnet.schedulers - Changing lr from 0.0001 to 9e-05
speechbrain.nnet.schedulers - Changing lr from 1e-05 to 9e-06
speechbrain.utils.train_logger - Epoch: 2, lr: 1.00e-04, ssl_lr: 1.00e-05 - train loss: 5.42e-01 - valid loss: 9.03e-01, valid acc: 5.00e-01, valid error_rate: 5.00e-01
speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /home/ulaval.ca/maelr5/scratch/parkinsons-results/train_with_wav2vec2/base/1986/save/CKPT+2025-04-04+15-08-52+00
speechbrain.utils.checkpoints - Deleted checkpoint in /home/ulaval.ca/maelr5/scratch/parkinsons-results/train_with_wav2vec2/base/1986/save/CKPT+2025-04-04+15-08-48+00
speechbrain.utils.epoch_loop - Going into epoch 3
  0%|          | 0/1 [00:00<?, ?it/s]                                       0%|          | 0/1 [00:00<?, ?it/s]wav length =  105
speechbrain.dataio.encoder - CategoricalEncoder.expect_len was never called: assuming category count of 2 to be correct! Sanity check your encoder using `.expect_len`. Ensure that downstream code also uses the correct size. If you are sure this does not apply to you, use `.ignore_len`.
  0%|          | 0/1 [00:01<?, ?it/s, train_loss=0.423]100%|██████████| 1/1 [00:01<00:00,  1.12s/it, train_loss=0.423]wav length =  119
100%|██████████| 1/1 [00:01<00:00,  1.15s/it, train_loss=0.423]
predictions shape=  torch.Size([2, 2])
detection_id shape=  torch.Size([2])
prediction tensor([[-0.7858, -0.6083],
        [-0.2376, -1.5535]], device='cuda:0', grad_fn=<LogSoftmaxBackward0>)
detection_id tensor([1, 0], device='cuda:0')
Predictions shape: torch.Size([2, 2])
Detection ID shape: torch.Size([2])
Lengths shape: torch.Size([2])
Predictions after argmax shape: torch.Size([2, 1, 2])
Detection ID target shape: torch.Size([2, 1])
  0%|          | 0/1 [00:00<?, ?it/s]                                       0%|          | 0/1 [00:00<?, ?it/s]wav length =  107
speechbrain.dataio.encoder - CategoricalEncoder.expect_len was never called: assuming category count of 2 to be correct! Sanity check your encoder using `.expect_len`. Ensure that downstream code also uses the correct size. If you are sure this does not apply to you, use `.ignore_len`.
100%|██████████| 1/1 [00:00<00:00,  2.61it/s]wav length =  110
100%|██████████| 1/1 [00:00<00:00,  2.38it/s]
predictions shape=  torch.Size([2, 2])
detection_id shape=  torch.Size([2])
prediction tensor([[-0.8949, -0.5254],
        [-0.2093, -1.6666]], device='cuda:0')
detection_id tensor([1, 1], device='cuda:0')
Predictions shape: torch.Size([2, 2])
Detection ID shape: torch.Size([2])
Lengths shape: torch.Size([2])
Predictions after argmax shape: torch.Size([2, 1, 2])
Detection ID target shape: torch.Size([2, 1])
speechbrain.nnet.schedulers - Changing lr from 9e-05 to 8.1e-05
speechbrain.nnet.schedulers - Changing lr from 9e-06 to 8.1e-06
speechbrain.utils.train_logger - Epoch: 3, lr: 9.00e-05, ssl_lr: 9.00e-06 - train loss: 4.23e-01 - valid loss: 1.10, valid acc: 5.00e-01, valid error_rate: 5.00e-01
speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /home/ulaval.ca/maelr5/scratch/parkinsons-results/train_with_wav2vec2/base/1986/save/CKPT+2025-04-04+15-08-55+00
speechbrain.utils.checkpoints - Deleted checkpoint in /home/ulaval.ca/maelr5/scratch/parkinsons-results/train_with_wav2vec2/base/1986/save/CKPT+2025-04-04+15-08-52+00
speechbrain.utils.epoch_loop - Going into epoch 4
  0%|          | 0/1 [00:00<?, ?it/s]                                       0%|          | 0/1 [00:00<?, ?it/s]wav length =  105
speechbrain.dataio.encoder - CategoricalEncoder.expect_len was never called: assuming category count of 2 to be correct! Sanity check your encoder using `.expect_len`. Ensure that downstream code also uses the correct size. If you are sure this does not apply to you, use `.ignore_len`.
  0%|          | 0/1 [00:01<?, ?it/s, train_loss=0.342]100%|██████████| 1/1 [00:01<00:00,  1.12s/it, train_loss=0.342]wav length =  119
100%|██████████| 1/1 [00:01<00:00,  1.15s/it, train_loss=0.342]
predictions shape=  torch.Size([2, 2])
detection_id shape=  torch.Size([2])
prediction tensor([[-0.8711, -0.5422],
        [-0.1422, -2.0206]], device='cuda:0', grad_fn=<LogSoftmaxBackward0>)
detection_id tensor([1, 0], device='cuda:0')
Predictions shape: torch.Size([2, 2])
Detection ID shape: torch.Size([2])
Lengths shape: torch.Size([2])
Predictions after argmax shape: torch.Size([2, 1, 2])
Detection ID target shape: torch.Size([2, 1])
  0%|          | 0/1 [00:00<?, ?it/s]                                       0%|          | 0/1 [00:00<?, ?it/s]wav length =  107
speechbrain.dataio.encoder - CategoricalEncoder.expect_len was never called: assuming category count of 2 to be correct! Sanity check your encoder using `.expect_len`. Ensure that downstream code also uses the correct size. If you are sure this does not apply to you, use `.ignore_len`.
100%|██████████| 1/1 [00:00<00:00,  2.62it/s]wav length =  110
100%|██████████| 1/1 [00:00<00:00,  2.40it/s]
predictions shape=  torch.Size([2, 2])
detection_id shape=  torch.Size([2])
prediction tensor([[-0.9906, -0.4642],
        [-0.1432, -2.0146]], device='cuda:0')
detection_id tensor([1, 1], device='cuda:0')
Predictions shape: torch.Size([2, 2])
Detection ID shape: torch.Size([2])
Lengths shape: torch.Size([2])
Predictions after argmax shape: torch.Size([2, 1, 2])
Detection ID target shape: torch.Size([2, 1])
speechbrain.nnet.schedulers - Changing lr from 8.1e-05 to 7.3e-05
speechbrain.nnet.schedulers - Changing lr from 8.1e-06 to 7.3e-06
speechbrain.utils.train_logger - Epoch: 4, lr: 8.10e-05, ssl_lr: 8.10e-06 - train loss: 3.42e-01 - valid loss: 1.24, valid acc: 5.00e-01, valid error_rate: 5.00e-01
speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /home/ulaval.ca/maelr5/scratch/parkinsons-results/train_with_wav2vec2/base/1986/save/CKPT+2025-04-04+15-09-02+00
speechbrain.utils.checkpoints - Deleted checkpoint in /home/ulaval.ca/maelr5/scratch/parkinsons-results/train_with_wav2vec2/base/1986/save/CKPT+2025-04-04+15-08-55+00
speechbrain.utils.epoch_loop - Going into epoch 5
  0%|          | 0/1 [00:00<?, ?it/s]                                       0%|          | 0/1 [00:00<?, ?it/s]wav length =  119
speechbrain.dataio.encoder - CategoricalEncoder.expect_len was never called: assuming category count of 2 to be correct! Sanity check your encoder using `.expect_len`. Ensure that downstream code also uses the correct size. If you are sure this does not apply to you, use `.ignore_len`.
  0%|          | 0/1 [00:01<?, ?it/s, train_loss=0.279]100%|██████████| 1/1 [00:01<00:00,  1.11s/it, train_loss=0.279]wav length =  105
100%|██████████| 1/1 [00:01<00:00,  1.15s/it, train_loss=0.279]
predictions shape=  torch.Size([2, 2])
detection_id shape=  torch.Size([2])
prediction tensor([[-0.0912, -2.4399],
        [-0.9850, -0.4675]], device='cuda:0', grad_fn=<LogSoftmaxBackward0>)
detection_id tensor([0, 1], device='cuda:0')
Predictions shape: torch.Size([2, 2])
Detection ID shape: torch.Size([2])
Lengths shape: torch.Size([2])
Predictions after argmax shape: torch.Size([2, 1, 2])
Detection ID target shape: torch.Size([2, 1])
  0%|          | 0/1 [00:00<?, ?it/s]                                       0%|          | 0/1 [00:00<?, ?it/s]wav length =  107
speechbrain.dataio.encoder - CategoricalEncoder.expect_len was never called: assuming category count of 2 to be correct! Sanity check your encoder using `.expect_len`. Ensure that downstream code also uses the correct size. If you are sure this does not apply to you, use `.ignore_len`.
100%|██████████| 1/1 [00:00<00:00,  2.56it/s]wav length =  110
100%|██████████| 1/1 [00:00<00:00,  2.35it/s]
predictions shape=  torch.Size([2, 2])
detection_id shape=  torch.Size([2])
prediction tensor([[-1.1048, -0.4024],
        [-0.1079, -2.2804]], device='cuda:0')
detection_id tensor([1, 1], device='cuda:0')
Predictions shape: torch.Size([2, 2])
Detection ID shape: torch.Size([2])
Lengths shape: torch.Size([2])
Predictions after argmax shape: torch.Size([2, 1, 2])
Detection ID target shape: torch.Size([2, 1])
speechbrain.nnet.schedulers - Changing lr from 7.3e-05 to 6.6e-05
speechbrain.nnet.schedulers - Changing lr from 7.3e-06 to 6.6e-06
speechbrain.utils.train_logger - Epoch: 5, lr: 7.29e-05, ssl_lr: 7.29e-06 - train loss: 2.79e-01 - valid loss: 1.34, valid acc: 5.00e-01, valid error_rate: 5.00e-01
speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /home/ulaval.ca/maelr5/scratch/parkinsons-results/train_with_wav2vec2/base/1986/save/CKPT+2025-04-04+15-09-08+00
speechbrain.utils.checkpoints - Deleted checkpoint in /home/ulaval.ca/maelr5/scratch/parkinsons-results/train_with_wav2vec2/base/1986/save/CKPT+2025-04-04+15-09-02+00
speechbrain.utils.checkpoints - Loading a checkpoint from /home/ulaval.ca/maelr5/scratch/parkinsons-results/train_with_wav2vec2/base/1986/save/CKPT+2025-04-04+15-09-08+00
  0%|          | 0/1 [00:00<?, ?it/s]                                       0%|          | 0/1 [00:00<?, ?it/s]wav length =  120
speechbrain.dataio.encoder - CategoricalEncoder.expect_len was never called: assuming category count of 2 to be correct! Sanity check your encoder using `.expect_len`. Ensure that downstream code also uses the correct size. If you are sure this does not apply to you, use `.ignore_len`.
100%|██████████| 1/1 [00:01<00:00,  1.54s/it]wav length =  108
100%|██████████| 1/1 [00:01<00:00,  1.57s/it]
predictions shape=  torch.Size([2, 2])
detection_id shape=  torch.Size([2])
test y_true=  [0 1]
test y_pred=  [1 0]
prediction tensor([[-0.8450, -0.5613],
        [-0.2082, -1.6713]], device='cuda:0')
detection_id tensor([0, 1], device='cuda:0')
Predictions shape: torch.Size([2, 2])
Detection ID shape: torch.Size([2])
Lengths shape: torch.Size([2])
Predictions after argmax shape: torch.Size([2, 1, 2])
Detection ID target shape: torch.Size([2, 1])
speechbrain.utils.train_logger - Epoch loaded: 5, 
 Per Class Accuracy: 
0: 0.000
1: 0.000, 
 Confusion Matrix: 
[[0 1]
 [1 0]]
 - test loss: 1.26, test acc: 0.00e+00, test error_rate: 1.00e+00
