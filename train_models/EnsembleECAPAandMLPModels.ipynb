{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc661194-127d-442c-9c1f-cfdc8d69e01c",
   "metadata": {},
   "source": [
    "# Parkinsons Disease Detection by Ensembling ECAPA and MLP models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928d8105-068c-4dba-8625-44afeda52c70",
   "metadata": {},
   "source": [
    "combine the strengths of two different models:\n",
    "\n",
    "- ECAPA-TDNN, which extracts strong temporal and speaker-discriminative embeddings,\n",
    "\n",
    "- MLP-based model, which might be tuned more directly for Parkinson’s detection.\n",
    "\n",
    "- ECAPA performs great on PD and the MLP seems more balanced when trained on pooled stats.\n",
    "\n",
    "- The idea is to fuse or ensemble their outputs to get a more robust final prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea805c2e-6072-469f-bf19-e47e8b9a2ce2",
   "metadata": {},
   "source": [
    "**One way is to do Feature Concatenation (Intermediate Fusion)**\n",
    "\n",
    "- Extract embeddings from ECAPA (xvector) and MLP (pooled stats), to learn complementary features.\n",
    "\n",
    "- Concatenate them into a single joint embedding.\n",
    "\n",
    "- Pass this through another classifier layer (like a small MLP)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e84d11fc-edd7-4254-a5b9-c917db507172",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed9f7666-de4d-474b-a2d9-81db06d04840",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-23 14:06:18.974395: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-04-23 14:06:19.535430: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-04-23 14:06:19.696584: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-23 14:06:20.826956: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-04-23 14:07:15.882885: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from plot_tensorboard import plot_training\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e76eeb2-8c6f-42c0-8fb4-49c3fadaddc9",
   "metadata": {},
   "source": [
    "### haprams file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4a7b1330-d628-4826-984a-148941423b49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting hparams_ecapamlpensembleavg_fbanks.yaml\n"
     ]
    }
   ],
   "source": [
    "%%file hparams_ecapamlpensembleavg_fbanks.yaml\n",
    "\n",
    "# Your code here\n",
    "# #################################\n",
    "# Basic training parameters for digit classification with Xvector\n",
    "#\n",
    "# Author:\n",
    "#  * Mirco Ravanelli 2021\n",
    "# #################################\n",
    "\n",
    "# Seed needs to be set at top of yaml, before objects with parameters are made\n",
    "seed: 1986\n",
    "__set_seed: !!python/object/apply:torch.manual_seed [!ref <seed>]\n",
    "\n",
    "data_folder: !ref /home/ulaval.ca/maelr5/scratch/parkinsons\n",
    "output_folder: !ref /home/ulaval.ca/maelr5/scratch/parkinsons-results/ecapamlpensembleavg/full_dataset/fbank/<seed>\n",
    "save_folder: !ref <output_folder>/save\n",
    "train_log: !ref <output_folder>/train_log.txt\n",
    "\n",
    "# Path where data manifest files are stored\n",
    "train_annotation: /home/ulaval.ca/maelr5/parkinsons/train.json\n",
    "valid_annotation: /home/ulaval.ca/maelr5/parkinsons/valid.json\n",
    "test_annotation: /home/ulaval.ca/maelr5/parkinsons/test.json\n",
    "\n",
    "# The train logger writes training statistics to a file, as well as stdout.\n",
    "train_logger: !new:speechbrain.utils.train_logger.FileTrainLogger\n",
    "    save_file: !ref <train_log>\n",
    "\n",
    "error_stats: !name:speechbrain.utils.metric_stats.MetricStats\n",
    "    metric: !name:speechbrain.nnet.losses.classification_error\n",
    "        reduction: batch\n",
    "\n",
    "# Feature parameters\n",
    "n_mels: 40\n",
    "\n",
    "# Training Parameters\n",
    "sample_rate: 16000\n",
    "number_of_epochs: 25\n",
    "batch_size: 4\n",
    "lr_start: 0.001\n",
    "lr_final: 0.0001\n",
    "n_classes: 2\n",
    "emb_dim: 192 # dimensionality of the embeddings\n",
    "emb_channels: [1024, 1024, 1024, 1024, 3072]\n",
    "emb_attention_channels: 128\n",
    "\n",
    "train_dataloader_options:\n",
    "    batch_size: !ref <batch_size>\n",
    "    shuffle: True\n",
    "    drop_last: True\n",
    "eval_dataloader_options:\n",
    "    batch_size: !ref <batch_size>\n",
    "    shuffle: False\n",
    "    drop_last: False\n",
    "\n",
    "# Tensorboard logs\n",
    "use_tensorboard: False\n",
    "tensorboard_logs_folder: !ref <output_folder>/tb_logs/\n",
    "\n",
    "# Feature extraction\n",
    "compute_features: !new:speechbrain.lobes.features.Fbank\n",
    "    n_mels: !ref <n_mels>\n",
    "# MODELS:-\n",
    "# Mean and std normalization of the input features\n",
    "mean_var_norm: !new:speechbrain.processing.features.InputNormalization\n",
    "    norm_type: global\n",
    "\n",
    "# ECAPA-TDNN\n",
    "embedding_model: !new:speechbrain.lobes.models.ECAPA_TDNN.ECAPA_TDNN\n",
    "    input_size: !ref <n_mels>\n",
    "    activation: !name:torch.nn.LeakyReLU\n",
    "    channels: !ref <emb_channels>\n",
    "    kernel_sizes: [5, 3, 3, 3, 1]\n",
    "    dilations: [1, 2, 3, 4, 1]\n",
    "    attention_channels: !ref <emb_attention_channels>\n",
    "    lin_neurons: !ref <emb_dim>\n",
    "# ECAPA-TDNN Classifier\n",
    "classifier: !new:speechbrain.lobes.models.ECAPA_TDNN.Classifier\n",
    "    input_size: !ref <emb_dim>\n",
    "    out_neurons: !ref <n_classes>\n",
    "\n",
    "# simple MLP\n",
    "avg_pool: !new:speechbrain.nnet.pooling.StatisticsPooling\n",
    "    return_std: False\n",
    "\n",
    "mlp_emb_dim: 512\n",
    "mlp1: !new:speechbrain.nnet.linear.Linear\n",
    "    input_size: !ref <n_mels>\n",
    "    n_neurons: !ref <mlp_emb_dim>\n",
    "    bias: False\n",
    "mlp2: !new:speechbrain.nnet.linear.Linear\n",
    "    input_size: !ref <mlp_emb_dim>\n",
    "    n_neurons: !ref <mlp_emb_dim>\n",
    "    bias: False\n",
    "\n",
    "# MLP classifier\n",
    "output_mlp: !new:speechbrain.nnet.linear.Linear\n",
    "    input_size: !ref <mlp_emb_dim>  # 192 (ECAPA) + 192 (MLP)\n",
    "    n_neurons: !ref <n_classes>\n",
    "    bias: False\n",
    "\n",
    "log_softmax: !new:speechbrain.nnet.activations.Softmax\n",
    "    apply_log: True\n",
    "\n",
    "# The first object passed to the Brain class is this \"Epoch Counter\"\n",
    "# which is saved by the Checkpointer so that training can be resumed\n",
    "# if it gets interrupted at any point.\n",
    "epoch_counter: !new:speechbrain.utils.epoch_loop.EpochCounter\n",
    "    limit: !ref <number_of_epochs>\n",
    "\n",
    "# Objects in \"modules\" dict will have their parameters moved to the correct\n",
    "# device, as well as having train()/eval() called on them by the Brain class.\n",
    "modules:\n",
    "    compute_features: !ref <compute_features>\n",
    "    mean_var_norm: !ref <mean_var_norm>\n",
    "    embedding_model: !ref <embedding_model>\n",
    "    classifier: !ref <classifier>\n",
    "    mlp1: !ref <mlp1>    \n",
    "    mlp2: !ref <mlp2>\n",
    "    output_mlp: !ref <output_mlp>\n",
    "\n",
    "# This optimizer will be constructed by the Brain class after all parameters\n",
    "# are moved to the correct device. Then it will be added to the checkpointer.\n",
    "opt_class: !name:torch.optim.Adam\n",
    "    lr: !ref <lr_start>\n",
    "\n",
    "# This function manages learning rate annealing over the epochs.\n",
    "# We here use the simple lr annealing method that linearly decreases\n",
    "# the lr from the initial value to the final one.\n",
    "lr_annealing: !new:speechbrain.nnet.schedulers.LinearScheduler\n",
    "    initial_value: !ref <lr_start>\n",
    "    final_value: !ref <lr_final>\n",
    "    epoch_count: !ref <number_of_epochs>\n",
    "\n",
    "# This object is used for saving the state of training both so that it\n",
    "# can be resumed if it gets interrupted, and also so that the best checkpoint\n",
    "# can be later loaded for evaluation or inference.\n",
    "checkpointer: !new:speechbrain.utils.checkpoints.Checkpointer\n",
    "    checkpoints_dir: !ref <save_folder>\n",
    "    recoverables:\n",
    "        embedding_model: !ref <embedding_model>\n",
    "        classifier: !ref <classifier>\n",
    "        mlp1: !ref <mlp1>    \n",
    "        mlp2: !ref <mlp2>\n",
    "        output_mlp: !ref <output_mlp>\n",
    "        normalizer: !ref <mean_var_norm>\n",
    "        counter: !ref <epoch_counter>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e6c6db-27f4-4402-ad9e-2f069af41daf",
   "metadata": {},
   "source": [
    "### train file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7771f1cb-0c81-4464-bf29-11126aa4907f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting train_ecapamlpensembleavg_fbanks.py\n"
     ]
    }
   ],
   "source": [
    "%%file train_ecapamlpensembleavg_fbanks.py\n",
    "# Your code here\n",
    "\n",
    "#!/usr/bin/env python3\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import torchaudio\n",
    "import speechbrain as sb\n",
    "from hyperpyyaml import load_hyperpyyaml\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from confusion_matrix_fig import create_cm_fig\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Brain class for speech enhancement training\n",
    "class DetectorBrain(sb.Brain):\n",
    "    \"\"\"Class that manages the training loop. See speechbrain.core.Brain.\"\"\"\n",
    "\n",
    "    def compute_forward(self, batch, stage):\n",
    "        \"\"\"Runs all the computations that transforms the input into the\n",
    "        output probabilities over the N classes.\n",
    "\n",
    "        Arguments\n",
    "        ---------\n",
    "        batch : PaddedBatch\n",
    "            This batch object contains all the relevant tensors for computation.\n",
    "        stage : sb.Stage\n",
    "            One of sb.Stage.TRAIN, sb.Stage.VALID, or sb.Stage.TEST.\n",
    "        Returns\n",
    "        -------\n",
    "        predictions : Tensor\n",
    "            Tensor that contains the posterior probabilities over the N classes.\n",
    "        \"\"\"\n",
    "        # Your code here. Aim for 7-8 lines\n",
    "        batch = batch.to(self.device)\n",
    "\n",
    "        # Feature extraction and normalization\n",
    "        wavs, lens = batch.sig\n",
    "        feats = self.modules.compute_features(wavs)\n",
    "        feats = self.modules.mean_var_norm(feats, lens)\n",
    "\n",
    "        # ECAPA\n",
    "        ecapa_emb = self.modules.embedding_model(feats)\n",
    "        ecapa_logits = self.modules.classifier(ecapa_emb)\n",
    "        \n",
    "        # MLP\n",
    "        pooled = self.hparams.avg_pool(feats, lens)\n",
    "        mlp_emb = self.modules.mlp1(pooled)\n",
    "        mlp_emb = self.modules.mlp2(mlp_emb)\n",
    "        mlp_logits = self.modules.output_mlp(mlp_emb)\n",
    "        \n",
    "        # Average logits\n",
    "        avg_logits = 0.5 * (0.7*ecapa_logits + (1 - 0.7)*mlp_logits)\n",
    "        \n",
    "        # Final prediction (for NLLLoss)\n",
    "        predictions = self.hparams.log_softmax(avg_logits)\n",
    "\n",
    "\n",
    "        # print(\"ECAPA shape:\", ecapa_emb.shape)\n",
    "        # print(\"MLP shape:\", mlp_emb.shape)\n",
    "        # print(\"Combined shape:\", combined_emb.shape)\n",
    "\n",
    "        return predictions\n",
    "\n",
    "\n",
    "    def compute_objectives(self, predictions, batch, stage):\n",
    "        \"\"\"Computes the loss given the predicted and targeted outputs.\n",
    "\n",
    "        Arguments\n",
    "        ---------\n",
    "        predictions : tensor\n",
    "            The output tensor from `compute_forward`.\n",
    "        batch : PaddedBatch\n",
    "            This batch object contains all the relevant tensors for computation.\n",
    "        stage : sb.Stage\n",
    "            One of sb.Stage.TRAIN, sb.Stage.VALID, or sb.Stage.TEST.\n",
    "        Returns\n",
    "        -------\n",
    "        loss : torch.Tensor\n",
    "            A one-element tensor used for backpropagating the gradient.\n",
    "        \"\"\"\n",
    "\n",
    "        # Your code here. Aim for 7-8 lines\n",
    "        _, lens = batch.sig\n",
    "        detection_id, _ = batch.detection_id_encoded\n",
    "        # print('prediction', predictions.shape)\n",
    "        # print('detection_id', detection_id.shape)\n",
    "\n",
    "        # Compute the cost function\n",
    "        loss = sb.nnet.losses.nll_loss(predictions, detection_id, lens)\n",
    "\n",
    "        # Append this batch of losses to the loss metric for easy\n",
    "        self.loss_metric.append(\n",
    "            batch.id, predictions, detection_id, lens, reduction=\"batch\"\n",
    "        )\n",
    "\n",
    "        # Compute classification error at test time\n",
    "        if stage != sb.Stage.TRAIN:\n",
    "            self.error_metrics.append(batch.id, predictions, detection_id, lens)\n",
    "\n",
    "        # Confusion matrices\n",
    "        if stage != sb.Stage.TRAIN:\n",
    "            y_true = detection_id.cpu().detach().numpy().squeeze(-1)\n",
    "            y_pred = predictions.cpu().detach().numpy().argmax(-1).squeeze(-1)\n",
    "        if stage == sb.Stage.TEST:\n",
    "            # print('test y_true= ', y_true)\n",
    "            # print('test y_pred= ', y_pred)\n",
    "            confusion_matix = confusion_matrix(\n",
    "                y_true,\n",
    "                y_pred,\n",
    "                labels=sorted(self.hparams.label_encoder.ind2lab.keys()),\n",
    "            )\n",
    "            self.test_confusion_matrix += confusion_matix\n",
    "\n",
    "        # Compute accuracy using MetricStats\n",
    "        self.acc_metric.append(\n",
    "            batch.id, predict=predictions, target=detection_id, lengths=lens\n",
    "        )\n",
    "\n",
    "        return loss\n",
    "\n",
    "\n",
    "    def on_stage_start(self, stage, epoch=None):\n",
    "        \"\"\"Gets called at the beginning of each epoch.\n",
    "        Arguments\n",
    "        ---------\n",
    "        stage : sb.Stage\n",
    "            One of sb.Stage.TRAIN, sb.Stage.VALID, or sb.Stage.TEST.\n",
    "        epoch : int\n",
    "            The currently-starting epoch. This is passed\n",
    "            `None` during the test stage.\n",
    "        \"\"\"\n",
    "\n",
    "        # Set up statistics trackers for this stage\n",
    "        self.loss_metric = sb.utils.metric_stats.MetricStats(\n",
    "            metric=sb.nnet.losses.nll_loss\n",
    "        )\n",
    "\n",
    "        # Compute accuracy using MetricStats\n",
    "        # Define function taking (prediction, target, length) for eval\n",
    "        def accuracy_value(predict, target, lengths):\n",
    "            \"\"\"Computes accuracy.\"\"\"\n",
    "            # print(\"Predictions shape:\", predict.shape)\n",
    "            # print(\"Detection ID shape:\", target.shape)\n",
    "            # print(\"Lengths shape:\", lengths.shape)\n",
    "            nbr_correct, nbr_total = sb.utils.Accuracy.Accuracy(\n",
    "                predict, target, lengths\n",
    "            )\n",
    "            acc = torch.tensor([nbr_correct / nbr_total])\n",
    "            return acc\n",
    "\n",
    "        self.acc_metric = sb.utils.metric_stats.MetricStats(\n",
    "            metric=accuracy_value, n_jobs=1\n",
    "        )\n",
    "        if stage == sb.Stage.TEST:\n",
    "            self.test_confusion_matrix = np.zeros(\n",
    "                shape=(self.hparams.n_classes, self.hparams.n_classes),\n",
    "                dtype=int,\n",
    "            )\n",
    "\n",
    "        # Set up evaluation-only statistics trackers\n",
    "        if stage != sb.Stage.TRAIN:\n",
    "            self.error_metrics = self.hparams.error_stats()\n",
    "\n",
    "    def on_stage_end(self, stage, stage_loss, epoch=None):\n",
    "        \"\"\"Gets called at the end of an epoch.\n",
    "        Arguments\n",
    "        ---------\n",
    "        stage : sb.Stage\n",
    "            One of sb.Stage.TRAIN, sb.Stage.VALID, sb.Stage.TEST\n",
    "        stage_loss : float\n",
    "            The average loss for all of the data processed in this stage.\n",
    "        epoch : int\n",
    "            The currently-starting epoch. This is passed\n",
    "            `None` during the test stage.\n",
    "        \"\"\"\n",
    "\n",
    "        # Store the train loss until the validation stage.\n",
    "        if stage == sb.Stage.TRAIN:\n",
    "            self.train_loss = stage_loss\n",
    "            self.train_stats = {\n",
    "                \"loss\": self.train_loss,\n",
    "                \"acc\": self.acc_metric.summarize(\"average\"),\n",
    "            }\n",
    "\n",
    "        # Summarize the statistics from the stage for record-keeping.\n",
    "        elif stage == sb.Stage.VALID:\n",
    "            valid_stats = {\n",
    "                \"loss\": stage_loss,\n",
    "                \"acc\": self.acc_metric.summarize(\"average\"),\n",
    "                \"error\": self.error_metrics.summarize(\"average\"),\n",
    "            }\n",
    "        # Summarize Test statistics from the stage for record-keeping\n",
    "        else:\n",
    "            test_stats = {\n",
    "                \"loss\": stage_loss,\n",
    "                \"acc\": self.acc_metric.summarize(\"average\"),\n",
    "                \"error\": self.error_metrics.summarize(\"average\"),\n",
    "            }\n",
    "\n",
    "        # At the end of validation...\n",
    "        if stage == sb.Stage.VALID:\n",
    "            old_lr, new_lr = self.hparams.lr_annealing(epoch)\n",
    "            sb.nnet.schedulers.update_learning_rate(self.optimizer, new_lr)\n",
    "\n",
    "            # Tensorboard logging\n",
    "            if self.hparams.use_tensorboard:\n",
    "                self.hparams.tensorboard_train_logger.log_stats(\n",
    "                    stats_meta={\"Epoch\": epoch},\n",
    "                    train_stats=self.train_stats,\n",
    "                    valid_stats=valid_stats,\n",
    "                )\n",
    "\n",
    "            # The train_logger writes a summary to stdout and to the logfile.\n",
    "            self.hparams.train_logger.log_stats(\n",
    "                {\"Epoch\": epoch, \"lr\": old_lr},\n",
    "                train_stats=self.train_stats,\n",
    "                valid_stats=valid_stats,\n",
    "            )\n",
    "\n",
    "            # Save the current checkpoint and delete previous checkpoints,\n",
    "            self.checkpointer.save_and_keep_only(meta=valid_stats, min_keys=[\"error\"])\n",
    "\n",
    "        # We also write statistics about test data to stdout and to the logfile.\n",
    "        if stage == sb.Stage.TEST:\n",
    "            # self.hparams.train_logger.log_stats(\n",
    "            #     {\"Epoch loaded\": self.hparams.epoch_counter.current},\n",
    "            #     test_stats=stats,\n",
    "            # )\n",
    "            # Per class accuracy from Test confusion matrix\n",
    "            per_class_acc_arr = np.diag(self.test_confusion_matrix) / np.sum(\n",
    "                self.test_confusion_matrix, axis=1\n",
    "            )\n",
    "            per_class_acc_arr_str = \"\\n\" + \"\\n\".join(\n",
    "                \"{:}: {:.3f}\".format(class_id, class_acc)\n",
    "                for class_id, class_acc in enumerate(per_class_acc_arr)\n",
    "            )\n",
    "\n",
    "            self.hparams.train_logger.log_stats(\n",
    "                {\n",
    "                    \"Epoch loaded\": self.hparams.epoch_counter.current,\n",
    "                    \"\\n Per Class Accuracy\": per_class_acc_arr_str,\n",
    "                    \"\\n Confusion Matrix\": \"\\n{:}\\n\".format(\n",
    "                        self.test_confusion_matrix\n",
    "                    ),\n",
    "                },\n",
    "                test_stats=test_stats,\n",
    "            )\n",
    "\n",
    "\n",
    "def dataio_prep(hparams):\n",
    "    \"\"\"This function prepares the datasets to be used in the brain class.\n",
    "    It also defines the data processing pipeline through user-defined functions.\n",
    "    We expect `prepare_mini_librispeech` to have been called before this,\n",
    "    so that the `train.json`, `valid.json`,  and `valid.json` manifest files\n",
    "    are available.\n",
    "    Arguments\n",
    "    ---------\n",
    "    hparams : dict\n",
    "        This dictionary is loaded from the `train.yaml` file, and it includes\n",
    "        all the hyperparameters needed for dataset construction and loading.\n",
    "    Returns\n",
    "    -------\n",
    "    datasets : dict\n",
    "        Contains two keys, \"train\" and \"valid\" that correspond\n",
    "        to the appropriate DynamicItemDataset object.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialization of the label encoder. The label encoder assigns to each\n",
    "    # of the observed label a unique index (e.g, 'digit0': 0, 'digit1': 1, ..)\n",
    "    label_encoder = sb.dataio.encoder.CategoricalEncoder()\n",
    "\n",
    "    # Define audio pipeline\n",
    "    @sb.utils.data_pipeline.takes(\"path\")\n",
    "    @sb.utils.data_pipeline.provides(\"sig\")\n",
    "    def audio_pipeline(wav):\n",
    "        \"\"\"Load the signal, and pass it and its length to the corruption class.\n",
    "        This is done on the CPU in the `collate_fn`.\"\"\"\n",
    "        sig, fs = torchaudio.load(wav)\n",
    "\n",
    "        # Resampling\n",
    "        # print('input signal(s) shape: ', sig.squeeze().shape)\n",
    "        sig = torchaudio.functional.resample(sig.squeeze(0), fs, hparams[\"sample_rate\"])\n",
    "        return sig\n",
    "\n",
    "    # Define label pipeline:\n",
    "    @sb.utils.data_pipeline.takes(\"detection\")\n",
    "    @sb.utils.data_pipeline.provides(\"detection\", \"detection_id_encoded\")\n",
    "    def label_pipeline(detection_id):\n",
    "        \"\"\"Defines the pipeline to process the detection labels.\n",
    "        Note that we have to assign a different integer to each class\n",
    "        through the label encoder.\n",
    "        \"\"\"\n",
    "        yield detection_id\n",
    "        detection_id_encoded = label_encoder.encode_label_torch(detection_id)\n",
    "        yield detection_id_encoded\n",
    "\n",
    "    # Define datasets. We also connect the dataset with the data processing\n",
    "    # functions defined above.\n",
    "    datasets = {}\n",
    "    data_info = {\n",
    "        \"train\": hparams[\"train_annotation\"],\n",
    "        \"valid\": hparams[\"valid_annotation\"],\n",
    "        \"test\": hparams[\"test_annotation\"],\n",
    "    }\n",
    "    # hparams[\"dataloader_options\"][\"shuffle\"] = True\n",
    "    for dataset in data_info:\n",
    "        datasets[dataset] = sb.dataio.dataset.DynamicItemDataset.from_json(\n",
    "            json_path=data_info[dataset],\n",
    "            dynamic_items=[audio_pipeline, label_pipeline],\n",
    "            output_keys=[\"id\", \"sig\", \"detection_id_encoded\"],\n",
    "        )\n",
    "\n",
    "    # Load or compute the label encoder (with multi-GPU DDP support)\n",
    "    # Please, take a look into the lab_enc_file to see the label to index\n",
    "    # mapping.\n",
    "    lab_enc_file = os.path.join(hparams[\"save_folder\"], \"label_encoder.txt\")\n",
    "    label_encoder.load_or_create(\n",
    "        path=lab_enc_file,\n",
    "        from_didatasets=[datasets[\"train\"]],\n",
    "        output_key=\"detection\",\n",
    "    )\n",
    "\n",
    "    return datasets, label_encoder\n",
    "\n",
    "\n",
    "# Recipe begins!\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # Reading command line arguments.\n",
    "    hparams_file, run_opts, overrides = sb.parse_arguments(sys.argv[1:])\n",
    "\n",
    "    # Load hyperparameters file with command-line overrides.\n",
    "    with open(hparams_file) as fin:\n",
    "        hparams = load_hyperpyyaml(fin,  overrides)\n",
    "\n",
    "    # Create experiment directory\n",
    "    sb.create_experiment_directory(\n",
    "        experiment_directory=hparams[\"output_folder\"],\n",
    "        hyperparams_to_save=hparams_file,\n",
    "        overrides=overrides,\n",
    "    )\n",
    "\n",
    "    # Tensorboard logging\n",
    "    if hparams[\"use_tensorboard\"]:\n",
    "        from speechbrain.utils.train_logger import TensorboardLogger\n",
    "\n",
    "        hparams[\"tensorboard_train_logger\"] = TensorboardLogger(\n",
    "            hparams[\"tensorboard_logs_folder\"]\n",
    "        )\n",
    "\n",
    "    # Create dataset objects \"train\", \"valid\", and \"test\".\n",
    "    datasets, label_encoder = dataio_prep(hparams)\n",
    "    \n",
    "    hparams[\"label_encoder\"] = label_encoder\n",
    "    class_labels = sorted(list(label_encoder.ind2lab.values()))\n",
    "    print(\"Class Labels:\", class_labels, list(label_encoder.lab2ind.values()))\n",
    "\n",
    "    # Initialize the Brain object to prepare for mask training.\n",
    "    detection_brain = DetectorBrain(\n",
    "        modules=hparams[\"modules\"],\n",
    "        opt_class=hparams[\"opt_class\"],\n",
    "        hparams=hparams,\n",
    "        run_opts=run_opts,\n",
    "        checkpointer=hparams[\"checkpointer\"],\n",
    "    )\n",
    "\n",
    "    # The `fit()` method iterates the training loop, calling the methods\n",
    "    # necessary to update the parameters of the model. Since all objects\n",
    "    # with changing state are managed by the Checkpointer, training can be\n",
    "    # stopped at any point, and will be resumed on next call.\n",
    "    detection_brain.fit(\n",
    "        epoch_counter=detection_brain.hparams.epoch_counter,\n",
    "        train_set=datasets[\"train\"],\n",
    "        valid_set=datasets[\"valid\"],\n",
    "        train_loader_kwargs=hparams[\"train_dataloader_options\"],\n",
    "        valid_loader_kwargs=hparams[\"eval_dataloader_options\"],\n",
    "    )\n",
    "\n",
    "    # Load the best checkpoint for evaluation\n",
    "    test_stats = detection_brain.evaluate(\n",
    "        test_set=datasets[\"test\"],\n",
    "        min_key=\"error\",\n",
    "        test_loader_kwargs=hparams[\"eval_dataloader_options\"],\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "dc512efc-4e3f-4e3c-a55d-6acd1c7abc24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ulaval.ca/maelr5/parkinsons/parksenv/lib/python3.11/site-packages/speechbrain/utils/autocast.py:188: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  wrapped_fwd = torch.cuda.amp.custom_fwd(fwd, cast_inputs=cast_inputs)\n",
      "speechbrain.utils.quirks - Applied quirks (see `speechbrain.utils.quirks`): [allow_tf32, disable_jit_profiling]\n",
      "speechbrain.utils.quirks - Excluded quirks specified by the `SB_DISABLE_QUIRKS` environment (comma-separated list): []\n",
      "speechbrain.core - Beginning experiment!\n",
      "speechbrain.core - Experiment folder: /home/ulaval.ca/maelr5/scratch/parkinsons-results/ecapamlpensembleavg/full_dataset/fbank/1986\n",
      "2025-04-23 18:44:27.667623: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-04-23 18:44:27.686825: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-04-23 18:44:27.692646: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-23 18:44:27.708249: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-04-23 18:44:30.697419: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "speechbrain.dataio.encoder - Load called, but CategoricalEncoder is not empty. Loaded data will overwrite everything. This is normal if there is e.g. an unk label defined at init.\n",
      "Class Labels: ['HC', 'PD'] [0, 1]\n",
      "speechbrain.core - Gradscaler enabled: `False`\n",
      "speechbrain.core - Using training precision: `--precision=fp32`\n",
      "speechbrain.core - Using evaluation precision: `--eval_precision=fp32`\n",
      "speechbrain.core - DetectorBrain Model Statistics:\n",
      "* Total Number of Trainable Parameters: 21.7M\n",
      "* Total Number of Parameters: 21.7M\n",
      "* Trainable Parameters represent 100.0000% of the total size.\n",
      "speechbrain.utils.checkpoints - Would load a checkpoint here, but none found yet.\n",
      "speechbrain.utils.epoch_loop - Going into epoch 1\n",
      "speechbrain.dataio.encoder - CategoricalEncoder.expect_len was never called: assuming category count of 2 to be correct! Sanity check your encoder using `.expect_len`. Ensure that downstream code also uses the correct size. If you are sure this does not apply to you, use `.ignore_len`.\n",
      "  0%|                                                   | 0/162 [00:00<?, ?it/s]prediction torch.Size([4, 1, 2])\n",
      "detection_id torch.Size([4, 1])\n",
      "  1%|▏                        | 1/162 [00:01<02:56,  1.10s/it, train_loss=0.728]prediction torch.Size([4, 1, 2])\n",
      "detection_id torch.Size([4, 1])\n",
      "  1%|▎                        | 2/162 [00:01<01:50,  1.45it/s, train_loss=0.708]prediction torch.Size([4, 1, 2])\n",
      "detection_id torch.Size([4, 1])\n",
      "  2%|▍                        | 3/162 [00:02<01:58,  1.35it/s, train_loss=0.754]\n",
      "speechbrain.core - Exception:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ulaval.ca/maelr5/parkinsons/train_models/train_ecapamlpensembleavg_fbanks.py\", line 372, in <module>\n",
      "    detection_brain.fit(\n",
      "  File \"/home/ulaval.ca/maelr5/parkinsons/parksenv/lib/python3.11/site-packages/speechbrain/core.py\", line 1575, in fit\n",
      "    self._fit_train(train_set=train_set, epoch=epoch, enable=enable)\n",
      "  File \"/home/ulaval.ca/maelr5/parkinsons/parksenv/lib/python3.11/site-packages/speechbrain/core.py\", line 1400, in _fit_train\n",
      "    loss = self.fit_batch(batch)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ulaval.ca/maelr5/parkinsons/parksenv/lib/python3.11/site-packages/speechbrain/core.py\", line 1199, in fit_batch\n",
      "    outputs = self.compute_forward(batch, sb.Stage.TRAIN)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ulaval.ca/maelr5/parkinsons/train_models/train_ecapamlpensembleavg_fbanks.py\", line 43, in compute_forward\n",
      "    ecapa_emb = self.modules.embedding_model(feats)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ulaval.ca/maelr5/parkinsons/parksenv/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ulaval.ca/maelr5/parkinsons/parksenv/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ulaval.ca/maelr5/parkinsons/parksenv/lib/python3.11/site-packages/speechbrain/lobes/models/ECAPA_TDNN.py\", line 548, in forward\n",
      "    x = self.mfa(x)\n",
      "        ^^^^^^^^^^^\n",
      "  File \"/home/ulaval.ca/maelr5/parkinsons/parksenv/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ulaval.ca/maelr5/parkinsons/parksenv/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ulaval.ca/maelr5/parkinsons/parksenv/lib/python3.11/site-packages/speechbrain/lobes/models/ECAPA_TDNN.py\", line 85, in forward\n",
      "    return self.dropout(self.norm(self.activation(self.conv(x))))\n",
      "                                                  ^^^^^^^^^^^^\n",
      "  File \"/home/ulaval.ca/maelr5/parkinsons/parksenv/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ulaval.ca/maelr5/parkinsons/parksenv/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ulaval.ca/maelr5/parkinsons/parksenv/lib/python3.11/site-packages/speechbrain/nnet/CNN.py\", line 455, in forward\n",
      "    wx = self.conv(x)\n",
      "         ^^^^^^^^^^^^\n",
      "  File \"/home/ulaval.ca/maelr5/parkinsons/parksenv/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ulaval.ca/maelr5/parkinsons/parksenv/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ulaval.ca/maelr5/parkinsons/parksenv/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 375, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ulaval.ca/maelr5/parkinsons/parksenv/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 370, in _conv_forward\n",
      "    return F.conv1d(\n",
      "           ^^^^^^^^^\n",
      "torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 896.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 30.19 MiB is free. Including non-PyTorch memory, this process has 15.73 GiB memory in use. Of the allocated memory 13.89 GiB is allocated by PyTorch, and 1.46 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    }
   ],
   "source": [
    "# Delete the output folder to start training from scratch (and not from a previous checkpoint).\n",
    "!rm -rf /home/ulaval.ca/maelr5/scratch/parkinsons-results/ecapamlpensembleavg/full_dataset/fbank/1986\n",
    "\n",
    "# Run Training\n",
    "!{sys.executable} train_ecapamlpensembleavg_fbanks.py hparams_ecapamlpensembleavg_fbanks.yaml --data_folder='/home/ulaval.ca/maelr5/scratch/parkinsons' --device='cuda:0' --number_of_epochs=15 --use_tensorboard=True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d9de7c-3355-4008-bead-53db464d6e36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "parksenv",
   "language": "python",
   "name": "parksenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
