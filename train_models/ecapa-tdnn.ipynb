{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95898c01-4e26-403a-a46d-5d1d9b50edd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a24afa16-a222-4a78-85b5-67241a1d5238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting hparams_ecapatdnn_fbanks.yaml\n"
     ]
    }
   ],
   "source": [
    "%%file hparams_ecapatdnn_fbanks.yaml\n",
    "# #################################\n",
    "# Training ECAPA-TDNN embeddings for language identification (LID).\n",
    "#\n",
    "# Authors:\n",
    "#  * Hwidong Na\n",
    "#  * Mirco Ravanelli\n",
    "#  * Pavlo Ruban\n",
    "# #################################\n",
    "\n",
    "# Seed needs to be set at top of yaml, before objects with parameters are made\n",
    "seed: 1986\n",
    "__set_seed: !apply:speechbrain.utils.seed_everything [!ref <seed>]\n",
    "\n",
    "# Set up folders for reading from and writing to\n",
    "# Dataset will be downloaded to the `data_folder`\n",
    "data_folder: !PLACEHOLDER # e.g. /localscratch/common_voice_kpd/\n",
    "output_folder: !ref /home/ulaval.ca/maelr5/scratch/parkinsons-results/ECAPA-TDNN/<seed>\n",
    "save_folder: !ref <output_folder>/save\n",
    "train_log: !ref <output_folder>/train_log.txt\n",
    "\n",
    "# Path where data manifest files are stored\n",
    "train_annotation: /home/ulaval.ca/maelr5/parkinsons/train-check.json\n",
    "valid_annotation: /home/ulaval.ca/maelr5/parkinsons/valid-check.json\n",
    "test_annotation: /home/ulaval.ca/maelr5/parkinsons/test-check.json\n",
    "\n",
    "skip_prep: False\n",
    "\n",
    "# The train logger writes training statistics to a file, as well as stdout.\n",
    "train_logger: !new:speechbrain.utils.train_logger.FileTrainLogger\n",
    "    save_file: !ref <train_log>\n",
    "\n",
    "error_stats: !name:speechbrain.utils.metric_stats.MetricStats\n",
    "    metric: !name:speechbrain.nnet.losses.classification_error\n",
    "        reduction: batch\n",
    "\n",
    "####################### Training Parameters ####################################\n",
    "\n",
    "# Feature parameters btw: 40 - 80\n",
    "n_mels: 40\n",
    "sample_rate: 16000\n",
    "number_of_epochs: 30\n",
    "batch_size: 2\n",
    "n_classes: 2\n",
    "emb_dim: 192 # dimensionality of the embeddings\n",
    "emb_channels: [1024, 1024, 1024, 1024, 3072]\n",
    "emb_attention_channels: 128\n",
    "\n",
    "# Dataloaders\n",
    "num_workers: 4\n",
    "drop_last: True\n",
    "train_dataloader_options:\n",
    "    num_workers: !ref <num_workers>\n",
    "    batch_size: !ref <batch_size>\n",
    "    drop_last: !ref <drop_last>\n",
    "    shuffle: True\n",
    "\n",
    "test_dataloader_options:\n",
    "    num_workers: !ref <num_workers>\n",
    "    batch_size: !ref <batch_size>\n",
    "    shuffle: True\n",
    "\n",
    "############################## Augmentations ###################################\n",
    "\n",
    "# Feature extraction\n",
    "compute_features: !new:speechbrain.lobes.features.Fbank\n",
    "    n_mels: !ref <n_mels>\n",
    "\n",
    "# Mean and std normalization of the input features\n",
    "mean_var_norm_input: !new:speechbrain.processing.features.InputNormalization\n",
    "    norm_type: sentence\n",
    "    std_norm: False\n",
    "\n",
    "############################## Models ##########################################\n",
    "\n",
    "# To design a custom model, either just edit the simple CustomModel\n",
    "# class that's listed here, or replace this `!new` call with a line\n",
    "# pointing to a different file you've defined.\n",
    "\n",
    "# Embedding Model\n",
    "embedding_model: !new:speechbrain.lobes.models.ECAPA_TDNN.ECAPA_TDNN\n",
    "    input_size: !ref <n_mels>\n",
    "    activation: !name:torch.nn.LeakyReLU\n",
    "    channels: !ref <emb_channels>\n",
    "    kernel_sizes: [5, 3, 3, 3, 1]\n",
    "    dilations: [1, 2, 3, 4, 1]\n",
    "    attention_channels: !ref <emb_attention_channels>\n",
    "    lin_neurons: !ref <emb_dim>\n",
    "\n",
    "# Classifier based on cosine distance\n",
    "classifier: !new:speechbrain.lobes.models.ECAPA_TDNN.Classifier\n",
    "    input_size: !ref <emb_dim>\n",
    "    out_neurons: !ref <n_classes>\n",
    "\n",
    "# The first object passed to the Brain class is this \"Epoch Counter\"\n",
    "# which is saved by the Checkpointer so that training can be resumed\n",
    "# if it gets interrupted at any point.\n",
    "epoch_counter: !new:speechbrain.utils.epoch_loop.EpochCounter\n",
    "    limit: !ref <number_of_epochs>\n",
    "\n",
    "# Objects in \"modules\" dict will have their parameters moved to the correct\n",
    "# device, as well as having train()/eval() called on them by the Brain class.\n",
    "modules:\n",
    "    compute_features: !ref <compute_features>\n",
    "    embedding_model: !ref <embedding_model>\n",
    "    mean_var_norm_input: !ref <mean_var_norm_input>\n",
    "    classifier: !ref <classifier>\n",
    "\n",
    "# Additive Angular Margin\n",
    "compute_cost: !new:speechbrain.nnet.losses.LogSoftmaxWrapper\n",
    "    loss_fn: !new:speechbrain.nnet.losses.AdditiveAngularMargin\n",
    "        margin: 0.2\n",
    "        scale: 30\n",
    "\n",
    "# Learning rates\n",
    "lr: 0.0001\n",
    "lr_final: 0.00001\n",
    "\n",
    "\n",
    "# This optimizer will be constructed by the Brain class after all parameters\n",
    "# are moved to the correct device. Then it will be added to the checkpointer.\n",
    "opt_class: !name:torch.optim.Adam\n",
    "    lr: !ref <lr>\n",
    "    weight_decay: 0.000002\n",
    "\n",
    "\n",
    "# Linear lr decay\n",
    "lr_annealing: !new:speechbrain.nnet.schedulers.LinearScheduler\n",
    "    initial_value: !ref <lr>\n",
    "    final_value: !ref <lr_final>\n",
    "    epoch_count: !ref <number_of_epochs>\n",
    "\n",
    "############################## Logging and Pretrainer ##########################\n",
    "\n",
    "# This object is used for saving the state of training both so that it\n",
    "# can be resumed if it gets interrupted, and also so that the best checkpoint\n",
    "# can be later loaded for evaluation or inference.\n",
    "checkpointer: !new:speechbrain.utils.checkpoints.Checkpointer\n",
    "    checkpoints_dir: !ref <save_folder>\n",
    "    recoverables:\n",
    "        normalizer_input: !ref <mean_var_norm_input>\n",
    "        embedding_model: !ref <embedding_model>\n",
    "        classifier: !ref <classifier>\n",
    "        counter: !ref <epoch_counter>\n",
    "\n",
    "# Load pretrained embedding module\n",
    "# Note: in this case, we pre-train with the ECAPA-TDNN model trained on voxceleb\n",
    "# for speaker-id (this leads to a performance improvement).\n",
    "embedding_model_path: speechbrain/spkrec-ecapa-voxceleb/embedding_model.ckpt\n",
    "\n",
    "# Pretrained ECAPA embeddings from SpeakerID on VoxCeleb\n",
    "pretrainer: !new:speechbrain.utils.parameter_transfer.Pretrainer\n",
    "    collect_in: !ref <save_folder>\n",
    "    loadables:\n",
    "        embedding_model: !ref <embedding_model>\n",
    "    paths:\n",
    "        embedding_model: !ref <embedding_model_path>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d25a53fd-8323-4dea-b4b0-f5e0b4a310cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting train_ecapatdnn_fbanks.py\n"
     ]
    }
   ],
   "source": [
    "%%file train_ecapatdnn_fbanks.py\n",
    "\n",
    "#!/usr/bin/env python3\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import torchaudio\n",
    "# from common_language_prepare import prepare_common_language\n",
    "from hyperpyyaml import load_hyperpyyaml\n",
    "\n",
    "import speechbrain as sb\n",
    "from speechbrain.utils.logger import get_logger\n",
    "\n",
    "\"\"\"Recipe for training a LID system with CommonLanguage.\n",
    "\n",
    "To run this recipe, do the following:\n",
    "> python train.py hparams/train_ecapa_tdnn.yaml\n",
    "\n",
    "Author\n",
    "------\n",
    " * Mirco Ravanelli 2021\n",
    " * Pavlo Ruban 2021\n",
    "\"\"\"\n",
    "\n",
    "# logger = get_logger(__name__)\n",
    "\n",
    "\n",
    "# Brain class for Language ID training\n",
    "class DetectorBrain(sb.Brain):\n",
    "    def prepare_features(self, wavs, stage):\n",
    "        \"\"\"Prepare the features for computation, including augmentation.\n",
    "\n",
    "        Arguments\n",
    "        ---------\n",
    "        wavs : tuple\n",
    "            Input signals (tensor) and their relative lengths (tensor).\n",
    "        stage : sb.Stage\n",
    "            The current stage of training.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        feats : torch.Tensor\n",
    "            Computed features.\n",
    "        lens : torch.Tensor\n",
    "            The length of the corresponding features.\n",
    "        \"\"\"\n",
    "        wavs, lens = wavs\n",
    "\n",
    "        # Feature extraction and normalization\n",
    "        feats = self.modules.compute_features(wavs)\n",
    "        feats = self.modules.mean_var_norm_input(feats, lens)\n",
    "\n",
    "        return feats, lens\n",
    "\n",
    "    def compute_forward(self, batch, stage):\n",
    "        \"\"\"Runs all the computation of that transforms the input into the\n",
    "        output probabilities over the N classes.\n",
    "\n",
    "        Arguments\n",
    "        ---------\n",
    "        batch : PaddedBatch\n",
    "            This batch object contains all the relevant tensors for computation.\n",
    "        stage : sb.Stage\n",
    "            One of sb.Stage.TRAIN, sb.Stage.VALID, or sb.Stage.TEST.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        predictions : torch.Tensor\n",
    "            torch.Tensor that contains the posterior probabilities over the N classes.\n",
    "        \"\"\"\n",
    "\n",
    "        # We first move the batch to the appropriate device.\n",
    "        batch = batch.to(self.device)\n",
    "\n",
    "        # Compute features, embeddings and output\n",
    "        feats, lens = self.prepare_features(batch.sig, stage)\n",
    "        embeddings = self.modules.embedding_model(feats)\n",
    "        outputs = self.modules.classifier(embeddings)\n",
    "\n",
    "        return outputs, lens\n",
    "\n",
    "    def compute_objectives(self, inputs, batch, stage):\n",
    "        \"\"\"Computes the loss given the predicted and targeted outputs.\n",
    "\n",
    "        Arguments\n",
    "        ---------\n",
    "        inputs : tensors\n",
    "            The output tensors from `compute_forward`.\n",
    "        batch : PaddedBatch\n",
    "            This batch object contains all the relevant tensors for computation.\n",
    "        stage : sb.Stage\n",
    "            One of sb.Stage.TRAIN, sb.Stage.VALID, or sb.Stage.TEST.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        loss : torch.Tensor\n",
    "            A one-element tensor used for backpropagating the gradient.\n",
    "        \"\"\"\n",
    "\n",
    "        predictions, lens = inputs\n",
    "\n",
    "        targets = batch.detection_id_encoded.data\n",
    "\n",
    "        # # Concatenate labels (due to data augmentation)\n",
    "        # if stage == sb.Stage.TRAIN:\n",
    "        #     if hasattr(self.hparams, \"wav_augment\"):\n",
    "        #         targets = self.hparams.wav_augment.replicate_labels(targets)\n",
    "        #         if hasattr(self.hparams.lr_annealing, \"on_batch_end\"):\n",
    "        #             self.hparams.lr_annealing.on_batch_end(self.optimizer)\n",
    "\n",
    "        loss = self.hparams.compute_cost(predictions, targets)\n",
    "\n",
    "        if stage != sb.Stage.TRAIN:\n",
    "            self.error_metrics.append(batch.id, predictions, targets, lens)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def on_stage_start(self, stage, epoch=None):\n",
    "        \"\"\"Gets called at the beginning of each epoch.\n",
    "\n",
    "        Arguments\n",
    "        ---------\n",
    "        stage : sb.Stage\n",
    "            One of sb.Stage.TRAIN, sb.Stage.VALID, or sb.Stage.TEST.\n",
    "        epoch : int\n",
    "            The currently-starting epoch. This is passed\n",
    "            `None` during the test stage.\n",
    "        \"\"\"\n",
    "\n",
    "        # Set up evaluation-only statistics trackers\n",
    "        if stage != sb.Stage.TRAIN:\n",
    "            self.error_metrics = self.hparams.error_stats()\n",
    "\n",
    "    def on_stage_end(self, stage, stage_loss, epoch=None):\n",
    "        \"\"\"Gets called at the end of an epoch.\n",
    "\n",
    "        Arguments\n",
    "        ---------\n",
    "        stage : sb.Stage\n",
    "            One of sb.Stage.TRAIN, sb.Stage.VALID, sb.Stage.TEST\n",
    "        stage_loss : float\n",
    "            The average loss for all of the data processed in this stage.\n",
    "        epoch : int\n",
    "            The currently-starting epoch. This is passed\n",
    "            `None` during the test stage.\n",
    "        \"\"\"\n",
    "\n",
    "        # Store the train loss until the validation stage.\n",
    "        if stage == sb.Stage.TRAIN:\n",
    "            self.train_loss = stage_loss\n",
    "\n",
    "        # Summarize the statistics from the stage for record-keeping.\n",
    "        else:\n",
    "            stats = {\n",
    "                \"loss\": stage_loss,\n",
    "                \"error\": self.error_metrics.summarize(\"average\"),\n",
    "            }\n",
    "\n",
    "        # At the end of validation...\n",
    "        if stage == sb.Stage.VALID:\n",
    "            old_lr, new_lr = self.hparams.lr_annealing(epoch)\n",
    "            sb.nnet.schedulers.update_learning_rate(self.optimizer, new_lr)\n",
    "\n",
    "            # The train_logger writes a summary to stdout and to the logfile.\n",
    "            self.hparams.train_logger.log_stats(\n",
    "                {\"Epoch\": epoch, \"lr\": old_lr},\n",
    "                train_stats={\"loss\": self.train_loss},\n",
    "                valid_stats=stats,\n",
    "            )\n",
    "\n",
    "            # Save the current checkpoint and delete previous checkpoints,\n",
    "            self.checkpointer.save_and_keep_only(meta=stats, min_keys=[\"error\"])\n",
    "\n",
    "        # We also write statistics about test data to stdout and to the logfile.\n",
    "        if stage == sb.Stage.TEST:\n",
    "            self.hparams.train_logger.log_stats(\n",
    "                {\"Epoch loaded\": self.hparams.epoch_counter.current},\n",
    "                test_stats=stats,\n",
    "            )\n",
    "\n",
    "\n",
    "def dataio_prep(hparams):\n",
    "    \"\"\"This function prepares the datasets to be used in the brain class.\n",
    "    It also defines the data processing pipeline through user-defined functions.\n",
    "    We expect `prepare_common_language` to have been called before this,\n",
    "    so that the `train.csv`, `valid.csv`,  and `test.csv` manifest files\n",
    "    are available.\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    hparams : dict\n",
    "        This dictionary is loaded from the `train.yaml` file, and it includes\n",
    "        all the hyperparameters needed for dataset construction and loading.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    datasets : dict\n",
    "        Contains two keys, \"train\" and \"dev\" that correspond\n",
    "        to the appropriate DynamicItemDataset object.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialization of the label encoder. The label encoder assigns to each\n",
    "    # of the observed label a unique index (e.g, 'lang01': 0, 'lang02': 1, ..)\n",
    "    label_encoder = sb.dataio.encoder.CategoricalEncoder()\n",
    "\n",
    "    # Define audio pipeline\n",
    "    @sb.utils.data_pipeline.takes(\"path\")\n",
    "    @sb.utils.data_pipeline.provides(\"sig\")\n",
    "    def audio_pipeline(wav):\n",
    "        \"\"\"Load the signal, and pass it and its length to the corruption class.\n",
    "        This is done on the CPU in the `collate_fn`.\"\"\"\n",
    "        sig, _ = torchaudio.load(wav)\n",
    "        # sig = torchaudio.functional.resample(sig.squeeze(0), fs, hparams[\"sample_rate\"])\n",
    "        sig = sig.transpose(0, 1).squeeze(1)\n",
    "\n",
    "        return sig\n",
    "\n",
    "    # Define label pipeline:\n",
    "    @sb.utils.data_pipeline.takes(\"detection\")\n",
    "    @sb.utils.data_pipeline.provides(\"detection\", \"detection_id_encoded\")\n",
    "    def label_pipeline(detection_id):\n",
    "        yield detection_id\n",
    "        detection_id_encoded = label_encoder.encode_label_torch(detection_id)\n",
    "        yield detection_id_encoded\n",
    "\n",
    "    # Define datasets. We also connect the dataset with the data processing\n",
    "    # functions defined above.\n",
    "    # datasets = {}\n",
    "    # for dataset in [\"train\", \"dev\", \"test\"]:\n",
    "    #     datasets[dataset] = sb.dataio.dataset.DynamicItemDataset.from_csv(\n",
    "    #         csv_path=hparams[f\"{dataset}_csv\"],\n",
    "    #         replacements={\"data_root\": hparams[\"data_folder\"]},\n",
    "    #         dynamic_items=[audio_pipeline, label_pipeline],\n",
    "    #         output_keys=[\"id\", \"sig\", \"language_encoded\"],\n",
    "    #     )\n",
    "\n",
    "    datasets = {}\n",
    "    data_info = {\n",
    "        \"train\": hparams[\"train_annotation\"],\n",
    "        \"valid\": hparams[\"valid_annotation\"],\n",
    "        \"test\": hparams[\"test_annotation\"],\n",
    "    }\n",
    "\n",
    "    for dataset in data_info:\n",
    "        datasets[dataset] = sb.dataio.dataset.DynamicItemDataset.from_json(\n",
    "            json_path=data_info[dataset],\n",
    "            replacements={\"data_root\": hparams[\"data_folder\"]},\n",
    "            dynamic_items=[audio_pipeline, label_pipeline],\n",
    "            output_keys=[\"id\", \"sig\", \"detection_id_encoded\"],\n",
    "        )\n",
    "\n",
    "    # Load or compute the label encoder (with multi-GPU DDP support)\n",
    "    # Please, take a look into the lab_enc_file to see the label to index\n",
    "    # mapping.\n",
    "    lab_enc_file = os.path.join(hparams[\"save_folder\"], \"label_encoder.txt\")\n",
    "    label_encoder.load_or_create(\n",
    "        path=lab_enc_file,\n",
    "        from_didatasets=[datasets[\"train\"]],\n",
    "        output_key=\"detection\",\n",
    "    )\n",
    "\n",
    "    return datasets, label_encoder\n",
    "\n",
    "\n",
    "# Recipe begins!\n",
    "if __name__ == \"__main__\":\n",
    "    # Reading command line arguments.\n",
    "    hparams_file, run_opts, overrides = sb.parse_arguments(sys.argv[1:])\n",
    "\n",
    "    # Load hyperparameters file with command-line overrides.\n",
    "    with open(hparams_file, encoding=\"utf-8\") as fin:\n",
    "        hparams = load_hyperpyyaml(fin, overrides)\n",
    "\n",
    "    # Create experiment directory\n",
    "    sb.create_experiment_directory(\n",
    "        experiment_directory=hparams[\"output_folder\"],\n",
    "        hyperparams_to_save=hparams_file,\n",
    "        overrides=overrides,\n",
    "    )\n",
    "\n",
    "    # Create dataset objects \"train\", \"valid\", and \"test\" and label_encoder\n",
    "    datasets, label_encoder = dataio_prep(hparams)\n",
    "\n",
    "    # Initialize the Brain object to prepare for mask training.\n",
    "    detection_brain = DetectorBrain(\n",
    "        modules=hparams[\"modules\"],\n",
    "        opt_class=hparams[\"opt_class\"],\n",
    "        hparams=hparams,\n",
    "        run_opts=run_opts,\n",
    "        checkpointer=hparams[\"checkpointer\"],\n",
    "    )\n",
    "\n",
    "    # The `fit()` method iterates the training loop, calling the methods\n",
    "    # necessary to update the parameters of the model. Since all objects\n",
    "    # with changing state are managed by the Checkpointer, training can be\n",
    "    # stopped at any point, and will be resumed on next call.\n",
    "    detection_brain.fit(\n",
    "        epoch_counter=detection_brain.hparams.epoch_counter,\n",
    "        train_set=datasets[\"train\"],\n",
    "        valid_set=datasets[\"valid\"],\n",
    "        train_loader_kwargs=hparams[\"train_dataloader_options\"],\n",
    "        valid_loader_kwargs=hparams[\"test_dataloader_options\"],\n",
    "    )\n",
    "\n",
    "    # Load the best checkpoint for evaluation\n",
    "    test_stats = detection_brain.evaluate(\n",
    "        test_set=datasets[\"test\"],\n",
    "        min_key=\"error\",\n",
    "        test_loader_kwargs=hparams[\"test_dataloader_options\"],\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e971fc76-375d-4327-be5e-0bbd8b8d4aed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ulaval.ca/maelr5/parkinsons/parksenv/lib/python3.11/site-packages/speechbrain/utils/autocast.py:188: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  wrapped_fwd = torch.cuda.amp.custom_fwd(fwd, cast_inputs=cast_inputs)\n",
      "speechbrain.utils.quirks - Applied quirks (see `speechbrain.utils.quirks`): [allow_tf32, disable_jit_profiling]\n",
      "speechbrain.utils.quirks - Excluded quirks specified by the `SB_DISABLE_QUIRKS` environment (comma-separated list): []\n",
      "speechbrain.core - Beginning experiment!\n",
      "speechbrain.core - Experiment folder: /home/ulaval.ca/maelr5/scratch/parkinsons-results/ECAPA-TDNN/1986\n",
      "speechbrain.dataio.encoder - Load called, but CategoricalEncoder is not empty. Loaded data will overwrite everything. This is normal if there is e.g. an unk label defined at init.\n",
      "speechbrain.core - Exception:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ulaval.ca/maelr5/parkinsons/train_models/train_ecapatdnn_fbanks.py\", line 284, in <module>\n",
      "    detection_brain = DetectorBrain(\n",
      "                      ^^^^^^^^^^^^^^\n",
      "  File \"/home/ulaval.ca/maelr5/parkinsons/parksenv/lib/python3.11/site-packages/speechbrain/core.py\", line 690, in __init__\n",
      "    self.modules = torch.nn.ModuleDict(modules).to(self.device)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ulaval.ca/maelr5/parkinsons/parksenv/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1343, in to\n",
      "    return self._apply(convert)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ulaval.ca/maelr5/parkinsons/parksenv/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 903, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/home/ulaval.ca/maelr5/parkinsons/parksenv/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 903, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/home/ulaval.ca/maelr5/parkinsons/parksenv/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 991, in _apply\n",
      "    self._buffers[key] = fn(buf)\n",
      "                         ^^^^^^^\n",
      "  File \"/home/ulaval.ca/maelr5/parkinsons/parksenv/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1329, in convert\n",
      "    return t.to(\n",
      "           ^^^^^\n",
      "RuntimeError: CUDA error: CUDA-capable device(s) is/are busy or unavailable\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import sys\n",
    "# Run Training\n",
    "!{sys.executable} train_ecapatdnn_fbanks.py hparams_ecapatdnn_fbanks.yaml  --data_folder='/home/ulaval.ca/maelr5/scratch/parkinsons' --device='cuda:0' # --number_of_epochs=5 --use_tensorboard=True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d980fbdd-cdd4-492f-9f9c-599d4fca56c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "parksenv",
   "language": "python",
   "name": "parksenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
