{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95898c01-4e26-403a-a46d-5d1d9b50edd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a24afa16-a222-4a78-85b5-67241a1d5238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting hparams_ecapatdnn_fbanks.yaml\n"
     ]
    }
   ],
   "source": [
    "%%file hparams_ecapatdnn_fbanks.yaml\n",
    "# #################################\n",
    "# Training ECAPA-TDNN embeddings for language identification (LID).\n",
    "#\n",
    "# Authors:\n",
    "#  * Hwidong Na\n",
    "#  * Mirco Ravanelli\n",
    "#  * Pavlo Ruban\n",
    "# #################################\n",
    "\n",
    "# Seed needs to be set at top of yaml, before objects with parameters are made\n",
    "seed: 1986\n",
    "__set_seed: !apply:speechbrain.utils.seed_everything [!ref <seed>]\n",
    "\n",
    "# Set up folders for reading from and writing to\n",
    "# Dataset will be downloaded to the `data_folder`\n",
    "data_folder: !PLACEHOLDER # e.g. /localscratch/common_voice_kpd/\n",
    "output_folder: !ref /home/ulaval.ca/maelr5/scratch/parkinsons-results/ECAPA-TDNN/full_dataset/fbank/<seed>\n",
    "save_folder: !ref <output_folder>/save\n",
    "train_log: !ref <output_folder>/train_log.txt\n",
    "\n",
    "# Path where data manifest files are stored\n",
    "train_annotation: /home/ulaval.ca/maelr5/parkinsons/train.json\n",
    "valid_annotation: /home/ulaval.ca/maelr5/parkinsons/valid.json\n",
    "test_annotation: /home/ulaval.ca/maelr5/parkinsons/test.json\n",
    "\n",
    "skip_prep: False\n",
    "\n",
    "# The train logger writes training statistics to a file, as well as stdout.\n",
    "train_logger: !new:speechbrain.utils.train_logger.FileTrainLogger\n",
    "    save_file: !ref <train_log>\n",
    "\n",
    "error_stats: !name:speechbrain.utils.metric_stats.MetricStats\n",
    "    metric: !name:speechbrain.nnet.losses.classification_error\n",
    "        reduction: batch\n",
    "\n",
    "####################### Training Parameters ####################################\n",
    "\n",
    "# Feature parameters btw: 40 - 80\n",
    "n_mels: 40\n",
    "sample_rate: 16000\n",
    "number_of_epochs: 15\n",
    "batch_size: 2\n",
    "n_classes: 2\n",
    "emb_dim: 192 # dimensionality of the embeddings\n",
    "emb_channels: [1024, 1024, 1024, 1024, 3072]\n",
    "emb_attention_channels: 128\n",
    "\n",
    "# Dataloaders\n",
    "num_workers: 4\n",
    "drop_last: True\n",
    "train_dataloader_options:\n",
    "    num_workers: !ref <num_workers>\n",
    "    batch_size: !ref <batch_size>\n",
    "    drop_last: !ref <drop_last>\n",
    "    shuffle: True\n",
    "\n",
    "test_dataloader_options:\n",
    "    num_workers: !ref <num_workers>\n",
    "    batch_size: !ref <batch_size>\n",
    "    shuffle: True\n",
    "\n",
    "############################## Augmentations ###################################\n",
    "\n",
    "# Feature extraction\n",
    "compute_features: !new:speechbrain.lobes.features.Fbank\n",
    "    n_mels: !ref <n_mels>\n",
    "\n",
    "# Mean and std normalization of the input features\n",
    "mean_var_norm_input: !new:speechbrain.processing.features.InputNormalization\n",
    "    norm_type: sentence\n",
    "    std_norm: False\n",
    "\n",
    "############################## Models ##########################################\n",
    "\n",
    "# To design a custom model, either just edit the simple CustomModel\n",
    "# class that's listed here, or replace this `!new` call with a line\n",
    "# pointing to a different file you've defined.\n",
    "\n",
    "# Embedding Model\n",
    "embedding_model: !new:speechbrain.lobes.models.ECAPA_TDNN.ECAPA_TDNN\n",
    "    input_size: !ref <n_mels>\n",
    "    activation: !name:torch.nn.LeakyReLU\n",
    "    channels: !ref <emb_channels>\n",
    "    kernel_sizes: [5, 3, 3, 3, 1]\n",
    "    dilations: [1, 2, 3, 4, 1]\n",
    "    attention_channels: !ref <emb_attention_channels>\n",
    "    lin_neurons: !ref <emb_dim>\n",
    "\n",
    "# Classifier based on cosine distance\n",
    "classifier: !new:speechbrain.lobes.models.ECAPA_TDNN.Classifier\n",
    "    input_size: !ref <emb_dim>\n",
    "    out_neurons: !ref <n_classes>\n",
    "\n",
    "# The first object passed to the Brain class is this \"Epoch Counter\"\n",
    "# which is saved by the Checkpointer so that training can be resumed\n",
    "# if it gets interrupted at any point.\n",
    "epoch_counter: !new:speechbrain.utils.epoch_loop.EpochCounter\n",
    "    limit: !ref <number_of_epochs>\n",
    "\n",
    "# Objects in \"modules\" dict will have their parameters moved to the correct\n",
    "# device, as well as having train()/eval() called on them by the Brain class.\n",
    "modules:\n",
    "    compute_features: !ref <compute_features>\n",
    "    embedding_model: !ref <embedding_model>\n",
    "    mean_var_norm_input: !ref <mean_var_norm_input>\n",
    "    classifier: !ref <classifier>\n",
    "\n",
    "# Additive Angular Margin\n",
    "compute_cost: !new:speechbrain.nnet.losses.LogSoftmaxWrapper\n",
    "    loss_fn: !new:speechbrain.nnet.losses.AdditiveAngularMargin\n",
    "        margin: 0.2\n",
    "        scale: 30\n",
    "\n",
    "# Learning rates\n",
    "lr: 0.0001\n",
    "lr_final: 0.00001\n",
    "\n",
    "\n",
    "# This optimizer will be constructed by the Brain class after all parameters\n",
    "# are moved to the correct device. Then it will be added to the checkpointer.\n",
    "opt_class: !name:torch.optim.Adam\n",
    "    lr: !ref <lr>\n",
    "    weight_decay: 0.000002\n",
    "\n",
    "\n",
    "# Linear lr decay\n",
    "lr_annealing: !new:speechbrain.nnet.schedulers.LinearScheduler\n",
    "    initial_value: !ref <lr>\n",
    "    final_value: !ref <lr_final>\n",
    "    epoch_count: !ref <number_of_epochs>\n",
    "\n",
    "############################## Logging and Pretrainer ##########################\n",
    "\n",
    "# This object is used for saving the state of training both so that it\n",
    "# can be resumed if it gets interrupted, and also so that the best checkpoint\n",
    "# can be later loaded for evaluation or inference.\n",
    "checkpointer: !new:speechbrain.utils.checkpoints.Checkpointer\n",
    "    checkpoints_dir: !ref <save_folder>\n",
    "    recoverables:\n",
    "        normalizer_input: !ref <mean_var_norm_input>\n",
    "        embedding_model: !ref <embedding_model>\n",
    "        classifier: !ref <classifier>\n",
    "        counter: !ref <epoch_counter>\n",
    "\n",
    "# Load pretrained embedding module\n",
    "# Note: in this case, we pre-train with the ECAPA-TDNN model trained on voxceleb\n",
    "# for speaker-id (this leads to a performance improvement).\n",
    "embedding_model_path: speechbrain/spkrec-ecapa-voxceleb/embedding_model.ckpt\n",
    "\n",
    "# Pretrained ECAPA embeddings from SpeakerID on VoxCeleb\n",
    "pretrainer: !new:speechbrain.utils.parameter_transfer.Pretrainer\n",
    "    collect_in: !ref <save_folder>\n",
    "    loadables:\n",
    "        embedding_model: !ref <embedding_model>\n",
    "    paths:\n",
    "        embedding_model: !ref <embedding_model_path>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d25a53fd-8323-4dea-b4b0-f5e0b4a310cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting train_ecapatdnn_fbanks.py\n"
     ]
    }
   ],
   "source": [
    "%%file train_ecapatdnn_fbanks.py\n",
    "\n",
    "#!/usr/bin/env python3\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import torchaudio\n",
    "# from common_language_prepare import prepare_common_language\n",
    "from hyperpyyaml import load_hyperpyyaml\n",
    "\n",
    "import speechbrain as sb\n",
    "from speechbrain.utils.logger import get_logger\n",
    "\n",
    "\"\"\"Recipe for training a LID system with CommonLanguage.\n",
    "\n",
    "To run this recipe, do the following:\n",
    "> python train.py hparams/train_ecapa_tdnn.yaml\n",
    "\n",
    "Author\n",
    "------\n",
    " * Mirco Ravanelli 2021\n",
    " * Pavlo Ruban 2021\n",
    "\"\"\"\n",
    "\n",
    "# logger = get_logger(__name__)\n",
    "\n",
    "\n",
    "# Brain class for Language ID training\n",
    "class DetectorBrain(sb.Brain):\n",
    "    def prepare_features(self, wavs, stage):\n",
    "        \"\"\"Prepare the features for computation, including augmentation.\n",
    "\n",
    "        Arguments\n",
    "        ---------\n",
    "        wavs : tuple\n",
    "            Input signals (tensor) and their relative lengths (tensor).\n",
    "        stage : sb.Stage\n",
    "            The current stage of training.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        feats : torch.Tensor\n",
    "            Computed features.\n",
    "        lens : torch.Tensor\n",
    "            The length of the corresponding features.\n",
    "        \"\"\"\n",
    "        wavs, lens = wavs\n",
    "\n",
    "        # Feature extraction and normalization\n",
    "        feats = self.modules.compute_features(wavs)\n",
    "        feats = self.modules.mean_var_norm_input(feats, lens)\n",
    "\n",
    "        return feats, lens\n",
    "\n",
    "    def compute_forward(self, batch, stage):\n",
    "        \"\"\"Runs all the computation of that transforms the input into the\n",
    "        output probabilities over the N classes.\n",
    "\n",
    "        Arguments\n",
    "        ---------\n",
    "        batch : PaddedBatch\n",
    "            This batch object contains all the relevant tensors for computation.\n",
    "        stage : sb.Stage\n",
    "            One of sb.Stage.TRAIN, sb.Stage.VALID, or sb.Stage.TEST.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        predictions : torch.Tensor\n",
    "            torch.Tensor that contains the posterior probabilities over the N classes.\n",
    "        \"\"\"\n",
    "\n",
    "        # We first move the batch to the appropriate device.\n",
    "        batch = batch.to(self.device)\n",
    "\n",
    "        # Compute features, embeddings and output\n",
    "        feats, lens = self.prepare_features(batch.sig, stage)\n",
    "        embeddings = self.modules.embedding_model(feats)\n",
    "        outputs = self.modules.classifier(embeddings)\n",
    "\n",
    "        return outputs, lens\n",
    "\n",
    "    def compute_objectives(self, inputs, batch, stage):\n",
    "        \"\"\"Computes the loss given the predicted and targeted outputs.\n",
    "\n",
    "        Arguments\n",
    "        ---------\n",
    "        inputs : tensors\n",
    "            The output tensors from `compute_forward`.\n",
    "        batch : PaddedBatch\n",
    "            This batch object contains all the relevant tensors for computation.\n",
    "        stage : sb.Stage\n",
    "            One of sb.Stage.TRAIN, sb.Stage.VALID, or sb.Stage.TEST.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        loss : torch.Tensor\n",
    "            A one-element tensor used for backpropagating the gradient.\n",
    "        \"\"\"\n",
    "\n",
    "        predictions, lens = inputs\n",
    "\n",
    "        targets = batch.detection_id_encoded.data\n",
    "\n",
    "        # # Concatenate labels (due to data augmentation)\n",
    "        # if stage == sb.Stage.TRAIN:\n",
    "        #     if hasattr(self.hparams, \"wav_augment\"):\n",
    "        #         targets = self.hparams.wav_augment.replicate_labels(targets)\n",
    "        #         if hasattr(self.hparams.lr_annealing, \"on_batch_end\"):\n",
    "        #             self.hparams.lr_annealing.on_batch_end(self.optimizer)\n",
    "\n",
    "        loss = self.hparams.compute_cost(predictions, targets)\n",
    "\n",
    "        if stage != sb.Stage.TRAIN:\n",
    "            self.error_metrics.append(batch.id, predictions, targets, lens)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def on_stage_start(self, stage, epoch=None):\n",
    "        \"\"\"Gets called at the beginning of each epoch.\n",
    "\n",
    "        Arguments\n",
    "        ---------\n",
    "        stage : sb.Stage\n",
    "            One of sb.Stage.TRAIN, sb.Stage.VALID, or sb.Stage.TEST.\n",
    "        epoch : int\n",
    "            The currently-starting epoch. This is passed\n",
    "            `None` during the test stage.\n",
    "        \"\"\"\n",
    "\n",
    "        # Set up evaluation-only statistics trackers\n",
    "        if stage != sb.Stage.TRAIN:\n",
    "            self.error_metrics = self.hparams.error_stats()\n",
    "\n",
    "    def on_stage_end(self, stage, stage_loss, epoch=None):\n",
    "        \"\"\"Gets called at the end of an epoch.\n",
    "\n",
    "        Arguments\n",
    "        ---------\n",
    "        stage : sb.Stage\n",
    "            One of sb.Stage.TRAIN, sb.Stage.VALID, sb.Stage.TEST\n",
    "        stage_loss : float\n",
    "            The average loss for all of the data processed in this stage.\n",
    "        epoch : int\n",
    "            The currently-starting epoch. This is passed\n",
    "            `None` during the test stage.\n",
    "        \"\"\"\n",
    "\n",
    "        # Store the train loss until the validation stage.\n",
    "        if stage == sb.Stage.TRAIN:\n",
    "            self.train_loss = stage_loss\n",
    "\n",
    "        # Summarize the statistics from the stage for record-keeping.\n",
    "        else:\n",
    "            stats = {\n",
    "                \"loss\": stage_loss,\n",
    "                \"error\": self.error_metrics.summarize(\"average\"),\n",
    "            }\n",
    "\n",
    "        # At the end of validation...\n",
    "        if stage == sb.Stage.VALID:\n",
    "            old_lr, new_lr = self.hparams.lr_annealing(epoch)\n",
    "            sb.nnet.schedulers.update_learning_rate(self.optimizer, new_lr)\n",
    "\n",
    "            # The train_logger writes a summary to stdout and to the logfile.\n",
    "            self.hparams.train_logger.log_stats(\n",
    "                {\"Epoch\": epoch, \"lr\": old_lr},\n",
    "                train_stats={\"loss\": self.train_loss},\n",
    "                valid_stats=stats,\n",
    "            )\n",
    "\n",
    "            # Save the current checkpoint and delete previous checkpoints,\n",
    "            self.checkpointer.save_and_keep_only(meta=stats, min_keys=[\"error\"])\n",
    "\n",
    "        # We also write statistics about test data to stdout and to the logfile.\n",
    "        if stage == sb.Stage.TEST:\n",
    "            self.hparams.train_logger.log_stats(\n",
    "                {\"Epoch loaded\": self.hparams.epoch_counter.current},\n",
    "                test_stats=stats,\n",
    "            )\n",
    "\n",
    "\n",
    "def dataio_prep(hparams):\n",
    "    \"\"\"This function prepares the datasets to be used in the brain class.\n",
    "    It also defines the data processing pipeline through user-defined functions.\n",
    "    We expect `prepare_common_language` to have been called before this,\n",
    "    so that the `train.csv`, `valid.csv`,  and `test.csv` manifest files\n",
    "    are available.\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    hparams : dict\n",
    "        This dictionary is loaded from the `train.yaml` file, and it includes\n",
    "        all the hyperparameters needed for dataset construction and loading.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    datasets : dict\n",
    "        Contains two keys, \"train\" and \"dev\" that correspond\n",
    "        to the appropriate DynamicItemDataset object.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialization of the label encoder. The label encoder assigns to each\n",
    "    # of the observed label a unique index (e.g, 'lang01': 0, 'lang02': 1, ..)\n",
    "    label_encoder = sb.dataio.encoder.CategoricalEncoder()\n",
    "\n",
    "    # Define audio pipeline\n",
    "    @sb.utils.data_pipeline.takes(\"path\")\n",
    "    @sb.utils.data_pipeline.provides(\"sig\")\n",
    "    def audio_pipeline(wav):\n",
    "        \"\"\"Load the signal, and pass it and its length to the corruption class.\n",
    "        This is done on the CPU in the `collate_fn`.\"\"\"\n",
    "        sig, _ = torchaudio.load(wav)\n",
    "        # sig = torchaudio.functional.resample(sig.squeeze(0), fs, hparams[\"sample_rate\"])\n",
    "        sig = sig.transpose(0, 1).squeeze(1)\n",
    "\n",
    "        return sig\n",
    "\n",
    "    # Define label pipeline:\n",
    "    @sb.utils.data_pipeline.takes(\"detection\")\n",
    "    @sb.utils.data_pipeline.provides(\"detection\", \"detection_id_encoded\")\n",
    "    def label_pipeline(detection_id):\n",
    "        yield detection_id\n",
    "        detection_id_encoded = label_encoder.encode_label_torch(detection_id)\n",
    "        yield detection_id_encoded\n",
    "\n",
    "    # Define datasets. We also connect the dataset with the data processing\n",
    "    # functions defined above.\n",
    "    # datasets = {}\n",
    "    # for dataset in [\"train\", \"dev\", \"test\"]:\n",
    "    #     datasets[dataset] = sb.dataio.dataset.DynamicItemDataset.from_csv(\n",
    "    #         csv_path=hparams[f\"{dataset}_csv\"],\n",
    "    #         replacements={\"data_root\": hparams[\"data_folder\"]},\n",
    "    #         dynamic_items=[audio_pipeline, label_pipeline],\n",
    "    #         output_keys=[\"id\", \"sig\", \"language_encoded\"],\n",
    "    #     )\n",
    "\n",
    "    datasets = {}\n",
    "    data_info = {\n",
    "        \"train\": hparams[\"train_annotation\"],\n",
    "        \"valid\": hparams[\"valid_annotation\"],\n",
    "        \"test\": hparams[\"test_annotation\"],\n",
    "    }\n",
    "\n",
    "    for dataset in data_info:\n",
    "        datasets[dataset] = sb.dataio.dataset.DynamicItemDataset.from_json(\n",
    "            json_path=data_info[dataset],\n",
    "            replacements={\"data_root\": hparams[\"data_folder\"]},\n",
    "            dynamic_items=[audio_pipeline, label_pipeline],\n",
    "            output_keys=[\"id\", \"sig\", \"detection_id_encoded\"],\n",
    "        )\n",
    "\n",
    "    # Load or compute the label encoder (with multi-GPU DDP support)\n",
    "    # Please, take a look into the lab_enc_file to see the label to index\n",
    "    # mapping.\n",
    "    lab_enc_file = os.path.join(hparams[\"save_folder\"], \"label_encoder.txt\")\n",
    "    label_encoder.load_or_create(\n",
    "        path=lab_enc_file,\n",
    "        from_didatasets=[datasets[\"train\"]],\n",
    "        output_key=\"detection\",\n",
    "    )\n",
    "\n",
    "    return datasets, label_encoder\n",
    "\n",
    "\n",
    "# Recipe begins!\n",
    "if __name__ == \"__main__\":\n",
    "    # Reading command line arguments.\n",
    "    hparams_file, run_opts, overrides = sb.parse_arguments(sys.argv[1:])\n",
    "\n",
    "    # Load hyperparameters file with command-line overrides.\n",
    "    with open(hparams_file, encoding=\"utf-8\") as fin:\n",
    "        hparams = load_hyperpyyaml(fin, overrides)\n",
    "\n",
    "    # Create experiment directory\n",
    "    sb.create_experiment_directory(\n",
    "        experiment_directory=hparams[\"output_folder\"],\n",
    "        hyperparams_to_save=hparams_file,\n",
    "        overrides=overrides,\n",
    "    )\n",
    "\n",
    "    # Create dataset objects \"train\", \"valid\", and \"test\" and label_encoder\n",
    "    datasets, label_encoder = dataio_prep(hparams)\n",
    "\n",
    "    # Initialize the Brain object to prepare for mask training.\n",
    "    detection_brain = DetectorBrain(\n",
    "        modules=hparams[\"modules\"],\n",
    "        opt_class=hparams[\"opt_class\"],\n",
    "        hparams=hparams,\n",
    "        run_opts=run_opts,\n",
    "        checkpointer=hparams[\"checkpointer\"],\n",
    "    )\n",
    "\n",
    "    # The `fit()` method iterates the training loop, calling the methods\n",
    "    # necessary to update the parameters of the model. Since all objects\n",
    "    # with changing state are managed by the Checkpointer, training can be\n",
    "    # stopped at any point, and will be resumed on next call.\n",
    "    detection_brain.fit(\n",
    "        epoch_counter=detection_brain.hparams.epoch_counter,\n",
    "        train_set=datasets[\"train\"],\n",
    "        valid_set=datasets[\"valid\"],\n",
    "        train_loader_kwargs=hparams[\"train_dataloader_options\"],\n",
    "        valid_loader_kwargs=hparams[\"test_dataloader_options\"],\n",
    "    )\n",
    "\n",
    "    # Load the best checkpoint for evaluation\n",
    "    test_stats = detection_brain.evaluate(\n",
    "        test_set=datasets[\"test\"],\n",
    "        min_key=\"error\",\n",
    "        test_loader_kwargs=hparams[\"test_dataloader_options\"],\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e971fc76-375d-4327-be5e-0bbd8b8d4aed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ulaval.ca/maelr5/parkinsons/parksenv/lib/python3.11/site-packages/speechbrain/utils/autocast.py:188: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  wrapped_fwd = torch.cuda.amp.custom_fwd(fwd, cast_inputs=cast_inputs)\n",
      "speechbrain.utils.quirks - Applied quirks (see `speechbrain.utils.quirks`): [allow_tf32, disable_jit_profiling]\n",
      "speechbrain.utils.quirks - Excluded quirks specified by the `SB_DISABLE_QUIRKS` environment (comma-separated list): []\n",
      "speechbrain.core - Beginning experiment!\n",
      "speechbrain.core - Experiment folder: /home/ulaval.ca/maelr5/scratch/parkinsons-results/ECAPA-TDNN/full_dataset/fbank/1986\n",
      "speechbrain.dataio.encoder - Load called, but CategoricalEncoder is not empty. Loaded data will overwrite everything. This is normal if there is e.g. an unk label defined at init.\n",
      "speechbrain.core - Gradscaler enabled: `False`\n",
      "speechbrain.core - Using training precision: `--precision=fp32`\n",
      "speechbrain.core - Using evaluation precision: `--eval_precision=fp32`\n",
      "speechbrain.core - DetectorBrain Model Statistics:\n",
      "* Total Number of Trainable Parameters: 20.6M\n",
      "* Total Number of Parameters: 20.6M\n",
      "* Trainable Parameters represent 100.0000% of the total size.\n",
      "speechbrain.utils.checkpoints - Would load a checkpoint here, but none found yet.\n",
      "speechbrain.utils.epoch_loop - Going into epoch 1\n",
      "speechbrain.dataio.encoder - CategoricalEncoder.expect_len was never called: assuming category count of 2 to be correct! Sanity check your encoder using `.expect_len`. Ensure that downstream code also uses the correct size. If you are sure this does not apply to you, use `.ignore_len`.\n",
      "speechbrain.dataio.encoder - CategoricalEncoder.expect_len was never called: assuming category count of 2 to be correct! Sanity check your encoder using `.expect_len`. Ensure that downstream code also uses the correct size. If you are sure this does not apply to you, use `.ignore_len`.\n",
      "speechbrain.dataio.encoder - CategoricalEncoder.expect_len was never called: assuming category count of 2 to be correct! Sanity check your encoder using `.expect_len`. Ensure that downstream code also uses the correct size. If you are sure this does not apply to you, use `.ignore_len`.\n",
      "speechbrain.dataio.encoder - CategoricalEncoder.expect_len was never called: assuming category count of 2 to be correct! Sanity check your encoder using `.expect_len`. Ensure that downstream code also uses the correct size. If you are sure this does not apply to you, use `.ignore_len`.\n",
      "  1%|â–Ž                         | 4/324 [00:03<04:01,  1.32it/s, train_loss=7.64]\n",
      "speechbrain.core - Exception:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ulaval.ca/maelr5/parkinsons/train_models/train_ecapatdnn_fbanks.py\", line 296, in <module>\n",
      "    detection_brain.fit(\n",
      "  File \"/home/ulaval.ca/maelr5/parkinsons/parksenv/lib/python3.11/site-packages/speechbrain/core.py\", line 1575, in fit\n",
      "    self._fit_train(train_set=train_set, epoch=epoch, enable=enable)\n",
      "  File \"/home/ulaval.ca/maelr5/parkinsons/parksenv/lib/python3.11/site-packages/speechbrain/core.py\", line 1400, in _fit_train\n",
      "    loss = self.fit_batch(batch)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ulaval.ca/maelr5/parkinsons/parksenv/lib/python3.11/site-packages/speechbrain/core.py\", line 1199, in fit_batch\n",
      "    outputs = self.compute_forward(batch, sb.Stage.TRAIN)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ulaval.ca/maelr5/parkinsons/train_models/train_ecapatdnn_fbanks.py\", line 76, in compute_forward\n",
      "    embeddings = self.modules.embedding_model(feats)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ulaval.ca/maelr5/parkinsons/parksenv/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ulaval.ca/maelr5/parkinsons/parksenv/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ulaval.ca/maelr5/parkinsons/parksenv/lib/python3.11/site-packages/speechbrain/lobes/models/ECAPA_TDNN.py\", line 548, in forward\n",
      "    x = self.mfa(x)\n",
      "        ^^^^^^^^^^^\n",
      "  File \"/home/ulaval.ca/maelr5/parkinsons/parksenv/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ulaval.ca/maelr5/parkinsons/parksenv/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ulaval.ca/maelr5/parkinsons/parksenv/lib/python3.11/site-packages/speechbrain/lobes/models/ECAPA_TDNN.py\", line 85, in forward\n",
      "    return self.dropout(self.norm(self.activation(self.conv(x))))\n",
      "                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ulaval.ca/maelr5/parkinsons/parksenv/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ulaval.ca/maelr5/parkinsons/parksenv/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ulaval.ca/maelr5/parkinsons/parksenv/lib/python3.11/site-packages/torch/nn/modules/activation.py\", line 828, in forward\n",
      "    return F.leaky_relu(input, self.negative_slope, self.inplace)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ulaval.ca/maelr5/parkinsons/parksenv/lib/python3.11/site-packages/torch/nn/functional.py\", line 1902, in leaky_relu\n",
      "    result = torch._C._nn.leaky_relu(input, negative_slope)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 362.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 222.25 MiB is free. Process 991594 has 25.80 GiB memory in use. Process 1071853 has 6.13 GiB memory in use. Including non-PyTorch memory, this process has 7.32 GiB memory in use. Of the allocated memory 6.08 GiB is allocated by PyTorch, and 735.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import sys\n",
    "# Run Training\n",
    "!{sys.executable} train_ecapatdnn_fbanks.py hparams_ecapatdnn_fbanks.yaml  --data_folder='/home/ulaval.ca/maelr5/scratch/parkinsons' --device='cuda:0' # --number_of_epochs=5 --use_tensorboard=True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a56c1af-a825-4fb3-970c-a052a0f56590",
   "metadata": {},
   "source": [
    "The output train_log file when running the run.sh file:\n",
    "\n",
    "```\n",
    "Epoch: 1, lr: 1.00e-04 - train loss: 4.20 - valid loss: 6.02, valid error: 3.28e-01\n",
    "Epoch: 2, lr: 9.36e-05 - train loss: 3.00 - valid loss: 4.95, valid error: 4.69e-01\n",
    "Epoch: 3, lr: 8.71e-05 - train loss: 2.50 - valid loss: 2.89, valid error: 3.91e-01\n",
    "Epoch: 4, lr: 8.07e-05 - train loss: 2.04 - valid loss: 2.33, valid error: 2.66e-01\n",
    "Epoch: 5, lr: 7.43e-05 - train loss: 1.89 - valid loss: 1.08, valid error: 1.56e-01\n",
    "Epoch: 6, lr: 6.79e-05 - train loss: 1.58 - valid loss: 1.46, valid error: 2.03e-01\n",
    "Epoch: 7, lr: 6.14e-05 - train loss: 1.42 - valid loss: 1.07, valid error: 1.41e-01\n",
    "Epoch: 8, lr: 5.50e-05 - train loss: 1.36 - valid loss: 1.88, valid error: 2.34e-01\n",
    "Epoch: 9, lr: 4.86e-05 - train loss: 1.31 - valid loss: 1.83, valid error: 2.19e-01\n",
    "Epoch: 10, lr: 4.21e-05 - train loss: 1.44 - valid loss: 9.76e-01, valid error: 9.38e-02\n",
    "Epoch: 11, lr: 3.57e-05 - train loss: 1.30 - valid loss: 1.44, valid error: 2.34e-01\n",
    "Epoch: 12, lr: 2.93e-05 - train loss: 1.22 - valid loss: 1.01, valid error: 1.09e-01\n",
    "Epoch: 13, lr: 2.29e-05 - train loss: 1.26 - valid loss: 1.02, valid error: 1.25e-01\n",
    "Epoch: 14, lr: 1.64e-05 - train loss: 1.25 - valid loss: 1.37, valid error: 1.56e-01\n",
    "Epoch: 15, lr: 1.00e-05 - train loss: 1.29 - valid loss: 1.11, valid error: 1.41e-01\n",
    "Epoch loaded: 10 - test loss: 2.02, test error: 2.09e-01\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a074cbc-d7c2-4d23-90f3-7cbf4e057761",
   "metadata": {},
   "source": [
    "### plot train/valid loss/accuracy during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9011d6-7c0d-4c48-adf1-067280b80d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_training(event_file):\n",
    "    # Extract data from the event file\n",
    "    step = []  # Store the global steps\n",
    "    values = []  # Store the values (e.g., loss or accuracy)\n",
    "    tags = []  # Store the tags (e.g., \"train_loss\", \"validation_accuracy\")\n",
    "    \n",
    "    for summary in tf.compat.v1.train.summary_iterator(event_file):\n",
    "        for value in summary.summary.value:\n",
    "            # You can filter out the tags you're interested in (e.g., \"train_loss\", \"accuracy\")\n",
    "            if value.HasField('simple_value'):  # Make sure it is a scalar value\n",
    "                tags.append(value.tag)\n",
    "                values.append(value.simple_value)\n",
    "                step.append(summary.step)\n",
    "    \n",
    "    # Plot the loss\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # Example: Plotting a specific tag (e.g., \"train_loss\")\n",
    "    for tag in set(tags):  # We loop through each unique tag\n",
    "        # print(tag)\n",
    "        if tag == 'error/valid':\n",
    "            continue\n",
    "        if tag == 'Epoch':\n",
    "            continue\n",
    "        if tag == 'acc/train':\n",
    "            continue\n",
    "        if tag == 'acc/valid':\n",
    "            continue\n",
    "        tag_indices = [i for i, t in enumerate(tags) if t == tag]\n",
    "        tag_steps = [step[i] for i in tag_indices]\n",
    "        tag_values = [values[i] for i in tag_indices]\n",
    "        \n",
    "        plt.plot(tag_steps, tag_values, label=tag)  # Plot each tag with its respective values\n",
    "    \n",
    "    # Customize plot\n",
    "    plt.xlabel('Step')\n",
    "    plt.ylabel('Value')\n",
    "    plt.title('Loss during training')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Show plot\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot the acc\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # Example: Plotting a specific tag (e.g., \"train_loss\")\n",
    "    for tag in set(tags):  # We loop through each unique tag\n",
    "        # print(tag)\n",
    "        if tag == 'error/valid':\n",
    "            continue\n",
    "        if tag == 'Epoch':\n",
    "            continue\n",
    "        if tag == 'loss/train':\n",
    "            continue\n",
    "        if tag == 'loss/valid':\n",
    "            continue\n",
    "        tag_indices = [i for i, t in enumerate(tags) if t == tag]\n",
    "        tag_steps = [step[i] for i in tag_indices]\n",
    "        tag_values = [values[i] for i in tag_indices]\n",
    "        \n",
    "        plt.plot(tag_steps, tag_values, label=tag)  # Plot each tag with its respective values\n",
    "    \n",
    "    # Customize plot\n",
    "    plt.xlabel('Step')\n",
    "    plt.ylabel('Value')\n",
    "    plt.title('Accuracy during training')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Show plot\n",
    "    plt.show()\n",
    "\n",
    "event_file = \"/home/ulaval.ca/maelr5/scratch/parkinsons-results/xvector/fulldataset/FBANKs/1986/tb_logs/events.out.tfevents.1745138757.ul-val-pr-gpu05.l.ul.ca.1159741.0\"\n",
    "plot_training(event_file)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "parksenv",
   "language": "python",
   "name": "parksenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
